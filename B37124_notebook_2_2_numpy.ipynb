{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Financial Trading with Python, 2nd Edition\n",
        "Cordell L. Tanny, CFA, FRM, FDP\n",
        "\n",
        "## Chapter 2: Setting up a Python Quantitative Workflow\n",
        "\n",
        "### Notebook 2.2: NumPy for Finance\n",
        "\n",
        "Version: 1\n",
        "\n",
        "Date of last revision: December 28, 2025\n",
        "\n",
        "**NumPy: The Hidden Engine**\n",
        "\n",
        "*Note and recommendation: Very often, you might want to experiment on your own as you go through this notebook. We recommend you save a copy of this notebook before you start adding cells or changing anything. This way you always have a pristine copy to go back to.*"
      ],
      "metadata": {
        "id": "hYDBX0A1RNI6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Why NumPy?\n",
        "\n",
        "If you have worked through Notebook 2.1, you are comfortable with Pandas. You can create DataFrames, manipulate time series, and combine datasets. So why do you need another library?\n",
        "\n",
        "The answer is that Pandas is built on NumPy. Every time you perform a calculation in Pandas, NumPy is doing the heavy lifting under the hood. The DataFrame you see on screen is essentially a collection of NumPy arrays with labels attached.\n",
        "\n",
        "For most day-to-day work, you do not need to think about this. Pandas handles everything for you. But there are three situations where you need to work with NumPy directly:\n",
        "\n",
        "1. **Speed:** When you need maximum performance for large datasets or repeated calculations, working directly with NumPy arrays is faster than Pandas.\n",
        "\n",
        "2. **Machine Learning:** Libraries like scikit-learn expect NumPy arrays as input, not DataFrames. You need to know how to extract arrays from your DataFrames and reshape them correctly.\n",
        "\n",
        "3. **Matrix Math:** Portfolio optimization, covariance matrices, and other financial calculations require matrix operations that NumPy handles natively.\n",
        "\n",
        "This notebook will teach you what you need to know to work confidently with NumPy in a financial context."
      ],
      "metadata": {
        "id": "CFLj0g5CRaBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Arrays vs DataFrames\n",
        "\n",
        "Before we dive into creating arrays, you need to understand how they differ from the DataFrames you already know. They are related but serve different purposes.\n",
        "\n",
        "**DataFrames have labels. Arrays do not.**\n",
        "\n",
        "A DataFrame has an index (row labels) and column names. These labels make it easy to slice data by date or select a column by name. An array is just numbers. No labels. If you want the third row, you ask for row index 2. There is no concept of asking for the row labeled \"2024-07-03\".\n",
        "\n",
        "**DataFrames can hold mixed data types. Arrays cannot.**\n",
        "\n",
        "A DataFrame can have one column of strings, another of floats, and another of integers. Each column maintains its own data type. An array requires all elements to be the same type. If you mix types, NumPy will convert everything to a common type, often in ways you did not expect. We will cover this in detail shortly.\n",
        "\n",
        "**DataFrames are built for tabular data. Arrays can be any shape.**\n",
        "\n",
        "DataFrames are always two-dimensional: rows and columns. Arrays can be one-dimensional (a single series of numbers), two-dimensional (a matrix), three-dimensional (a cube of numbers), or higher. This flexibility is essential for machine learning where you often work with multi-dimensional data.\n",
        "\n",
        "**DataFrames have built-in time series methods. Arrays are for raw computation.**\n",
        "\n",
        "Methods like `.resample()`, `.rolling()`, and `.shift()` are Pandas features. NumPy arrays do not have these. Arrays are designed for fast numerical computation, not for time series manipulation.\n",
        "\n",
        "Let's see these differences in practice."
      ],
      "metadata": {
        "id": "J2l1Z35ESarS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a simple DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Price': [100, 102, 105],\n",
        "    'Volume': [1000, 1500, 1200]\n",
        "}, index=['2024-07-01', '2024-07-02', '2024-07-03'])\n",
        "\n",
        "print(\"DataFrame:\")\n",
        "print(df)\n",
        "print(f\"\\nAccess by label: df.loc['2024-07-02', 'Price'] = {df.loc['2024-07-02', 'Price']}\")\n",
        "\n",
        "# Extract as a NumPy array\n",
        "price_array = df['Price'].values\n",
        "\n",
        "print(\"\\nNumPy Array:\")\n",
        "print(price_array)\n",
        "print(f\"\\nAccess by position: price_array[1] = {price_array[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcPjtG_DScwY",
        "outputId": "615f63f7-b5dd-46ef-9385-7749b72ed0f6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame:\n",
            "            Price  Volume\n",
            "2024-07-01    100    1000\n",
            "2024-07-02    102    1500\n",
            "2024-07-03    105    1200\n",
            "\n",
            "Access by label: df.loc['2024-07-02', 'Price'] = 102\n",
            "\n",
            "NumPy Array:\n",
            "[100 102 105]\n",
            "\n",
            "Access by position: price_array[1] = 102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the difference. With the DataFrame, we accessed the value using the date label and column name. With the array, we only have position. The label information is gone.\n",
        "\n",
        "This is the trade-off. When you convert a DataFrame to an array, you lose the labels but you gain speed and compatibility with machine learning libraries.\n",
        "\n",
        "**When to use each:**\n",
        "\n",
        "Use DataFrames when you are working with time series data, need to combine datasets, or want the convenience of labeled access.\n",
        "\n",
        "Use NumPy arrays when you need maximum speed, are preparing data for machine learning, or are performing matrix operations like portfolio optimization.\n",
        "\n",
        "In practice, you will use both. Most of your data manipulation happens in Pandas. When you need to feed data into a model or perform heavy numerical computation, you extract arrays from your DataFrames."
      ],
      "metadata": {
        "id": "DsEBSKJHSfce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Creating Arrays\n",
        "\n",
        "Before we can work with NumPy, we need to understand how to create arrays. An array is simply a collection of values, similar to a list in Python but with important differences that we will explore.\n",
        "\n",
        "Let's start by importing NumPy. The convention is to import it as `np`."
      ],
      "metadata": {
        "id": "N7FGUEFtR4gN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NVneBPMcOdrv"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.1 np.array(): Converting Lists to Arrays\n",
        "\n",
        "The most common way to create an array is to convert a Python list using `np.array()`. This is how you will typically create arrays from data you already have."
      ],
      "metadata": {
        "id": "DB4ia9oHR8El"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an array from a list of prices\n",
        "prices = [100, 102, 101, 105, 108]\n",
        "price_array = np.array(prices)\n",
        "\n",
        "print(\"Original list:\", prices)\n",
        "print(\"NumPy array:\", price_array)\n",
        "print(\"Type:\", type(price_array))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MTFX9yQR658",
        "outputId": "d185cbc7-50d9-4b59-8feb-f80d8601fa07"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original list: [100, 102, 101, 105, 108]\n",
            "NumPy array: [100 102 101 105 108]\n",
            "Type: <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the array looks similar to the list, but it is a different object entirely. The type is `numpy.ndarray`, which stands for n-dimensional array.\n",
        "\n",
        "You can also create arrays from nested lists to make 2D arrays (matrices)."
      ],
      "metadata": {
        "id": "xVdNbrnrSEU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 2D array (matrix) from nested lists\n",
        "# Each inner list becomes a row\n",
        "returns_matrix = np.array([\n",
        "    [0.01, 0.02, -0.01],   # Asset 1 returns\n",
        "    [0.02, -0.01, 0.03],   # Asset 2 returns\n",
        "    [0.00, 0.01, 0.02]     # Asset 3 returns\n",
        "])\n",
        "\n",
        "print(\"2D Array (Matrix):\")\n",
        "print(returns_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld4XSpDWR9uN",
        "outputId": "b9cb18c0-4b16-42db-99fe-2563c05478e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2D Array (Matrix):\n",
            "[[ 0.01  0.02 -0.01]\n",
            " [ 0.02 -0.01  0.03]\n",
            " [ 0.    0.01  0.02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.2 np.zeros() and np.ones(): Initializing Arrays\n",
        "\n",
        "Sometimes you need to create an array of a specific size filled with placeholder values. This is common when you are building an array that you will populate later, such as storing results from a loop or creating a template for portfolio weights."
      ],
      "metadata": {
        "id": "8j4tb4aLS0a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an array of zeros (useful for initializing results)\n",
        "zeros_array = np.zeros(5)\n",
        "print(\"Array of zeros:\", zeros_array)\n",
        "\n",
        "# Create a 2D array of zeros (3 rows, 4 columns)\n",
        "zeros_matrix = np.zeros((3, 4))\n",
        "print(\"\\nMatrix of zeros:\")\n",
        "print(zeros_matrix)\n",
        "\n",
        "# Create an array of ones (useful for equal-weight portfolios)\n",
        "ones_array = np.ones(4)\n",
        "print(\"\\nArray of ones:\", ones_array)\n",
        "\n",
        "# Equal weight portfolio: divide by number of assets\n",
        "num_assets = 4\n",
        "equal_weights = np.ones(num_assets) / num_assets\n",
        "print(\"\\nEqual weight portfolio:\", equal_weights)\n",
        "print(\"Sum of weights:\", equal_weights.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UiJ98AwSy6c",
        "outputId": "1d218978-bcb9-4486-8f10-429763658605"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array of zeros: [0. 0. 0. 0. 0.]\n",
            "\n",
            "Matrix of zeros:\n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n",
            "\n",
            "Array of ones: [1. 1. 1. 1.]\n",
            "\n",
            "Equal weight portfolio: [0.25 0.25 0.25 0.25]\n",
            "Sum of weights: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The equal weight portfolio example is one you will use often. If you have four assets and want to allocate equally to each, you create an array of ones and divide by the number of assets. The weights sum to 1, as they should.\n",
        "\n",
        "Notice that when creating a 2D array, we pass the shape as a tuple: `(3, 4)` means 3 rows and 4 columns."
      ],
      "metadata": {
        "id": "_hVzKmp0TAya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.3 np.arange() and np.linspace(): Generating Sequences\n",
        "\n",
        "When you need a sequence of numbers, NumPy provides two useful functions. The `np.arange()` function works like Python's `range()` but returns an array. The `np.linspace()` function creates evenly spaced numbers between two endpoints."
      ],
      "metadata": {
        "id": "qH58bFR0TILN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# np.arange: start, stop, step (stop is excluded)\n",
        "sequence = np.arange(0, 10, 2)\n",
        "print(\"np.arange(0, 10, 2):\", sequence)\n",
        "\n",
        "# np.linspace: start, stop, number of points (stop is included)\n",
        "# Useful for creating strike prices for an options chain\n",
        "strike_prices = np.linspace(90, 110, 5)\n",
        "print(\"\\nStrike prices from 90 to 110 (5 points):\", strike_prices)\n",
        "\n",
        "# Creating percentage thresholds\n",
        "thresholds = np.linspace(0, 1, 11)\n",
        "print(\"\\nPercentage thresholds (0% to 100%):\", thresholds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lKJzhfDSHRa",
        "outputId": "c9a2507e-21c9-4fec-d34e-aab2651d2bbe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "np.arange(0, 10, 2): [0 2 4 6 8]\n",
            "\n",
            "Strike prices from 90 to 110 (5 points): [ 90.  95. 100. 105. 110.]\n",
            "\n",
            "Percentage thresholds (0% to 100%): [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key difference: `np.arange()` uses a step size, while `np.linspace()` uses a count. Use `np.arange()` when you know the step you want. Use `np.linspace()` when you know how many points you need between two values."
      ],
      "metadata": {
        "id": "XANfZW7HTPmB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.4 np.random: Generating Random Data for Simulations\n",
        "\n",
        "Random number generation is essential for Monte Carlo simulations, bootstrapping, and testing trading strategies with synthetic data. NumPy provides a comprehensive random module."
      ],
      "metadata": {
        "id": "krDy5aSJTSI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate random returns from a normal distribution\n",
        "# mean = 0.001 (0.1% daily return), std = 0.02 (2% daily volatility)\n",
        "random_returns = np.random.normal(loc=0.001, scale=0.02, size=10)\n",
        "print(\"Random daily returns:\")\n",
        "print(random_returns)\n",
        "\n",
        "# Generate random integers (useful for random sampling)\n",
        "random_indices = np.random.randint(0, 100, size=5)\n",
        "print(\"\\nRandom indices:\", random_indices)\n",
        "\n",
        "# Generate uniform random numbers between 0 and 1\n",
        "random_weights = np.random.random(4)\n",
        "# Normalize to sum to 1 (creating random portfolio weights)\n",
        "random_weights = random_weights / random_weights.sum()\n",
        "print(\"\\nRandom portfolio weights:\", random_weights)\n",
        "print(\"Sum:\", random_weights.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKdPjCfATJ6W",
        "outputId": "b26b1e4b-3ca4-4e42-d177-2fc16fe90623"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random daily returns:\n",
            "[ 0.01093428 -0.00176529  0.01395377  0.0314606  -0.00368307 -0.00368274\n",
            "  0.03258426  0.01634869 -0.00838949  0.0118512 ]\n",
            "\n",
            "Random indices: [63 59 20 32 75]\n",
            "\n",
            "Random portfolio weights: [0.52432363 0.0060574  0.01976966 0.44984931]\n",
            "Sum: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting a seed with `np.random.seed()` ensures your results are reproducible. Every time you run the code with the same seed, you get the same random numbers. This is critical for debugging and for sharing results with colleagues.\n",
        "\n",
        "The normal distribution example is particularly important. Most financial models assume returns are normally distributed (even though they are not quite). Simulating returns with `np.random.normal()` is the foundation of Monte Carlo analysis.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "uSlC58sETYhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 The Homogeneity Rule\n",
        "\n",
        "One of the most important differences between arrays and DataFrames is that arrays require all elements to be the same data type. This is called homogeneity. DataFrames can have different types in different columns. Arrays cannot.\n",
        "\n",
        "This is not just a technical detail. It is the reason arrays are fast. When NumPy knows that every element is the same type, it can perform calculations efficiently without checking each element individually."
      ],
      "metadata": {
        "id": "Qx_d-6l7Tbqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.1 Why Arrays Require a Single Data Type\n",
        "\n",
        "When you create an array, NumPy allocates a contiguous block of memory where each element takes the same amount of space. This allows NumPy to perform calculations on the entire array at once, rather than element by element. If the types were mixed, NumPy would need to check each element before operating on it, which would destroy the performance advantage."
      ],
      "metadata": {
        "id": "uaPEIIJFTjsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An array of floats\n",
        "float_array = np.array([1.5, 2.5, 3.5])\n",
        "print(\"Float array:\", float_array)\n",
        "print(\"Data type:\", float_array.dtype)\n",
        "\n",
        "# An array of integers\n",
        "int_array = np.array([1, 2, 3])\n",
        "print(\"\\nInteger array:\", int_array)\n",
        "print(\"Data type:\", int_array.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yD7L2_zTWF2",
        "outputId": "bf3d734b-e9cb-4450-e9bb-4549ce233ec7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Float array: [1.5 2.5 3.5]\n",
            "Data type: float64\n",
            "\n",
            "Integer array: [1 2 3]\n",
            "Data type: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.2 What Happens When You Mix Types\n",
        "\n",
        "Here is where beginners get into trouble. If you create an array with mixed types, NumPy will silently convert everything to a common type. It does not warn you. It just picks a type that can represent all the values."
      ],
      "metadata": {
        "id": "soNmFpD5To6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mix integers and floats: everything becomes float\n",
        "mixed_numeric = np.array([1, 2, 3.5])\n",
        "print(\"Mixed int and float:\", mixed_numeric)\n",
        "print(\"Data type:\", mixed_numeric.dtype)\n",
        "\n",
        "# Mix numbers and strings: everything becomes string\n",
        "mixed_with_string = np.array([1, 2, 'three'])\n",
        "print(\"\\nMixed with string:\", mixed_with_string)\n",
        "print(\"Data type:\", mixed_with_string.dtype)\n",
        "\n",
        "# The danger: try to do math on the string array\n",
        "try:\n",
        "    result = mixed_with_string * 2\n",
        "    print(\"\\nMultiply by 2:\", result)\n",
        "except TypeError as e:\n",
        "    print(\"\\nError:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bog_TTVxTnMo",
        "outputId": "73930fd1-877d-46e6-9fb6-3f2a8e3ae1f5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mixed int and float: [1.  2.  3.5]\n",
            "Data type: float64\n",
            "\n",
            "Mixed with string: ['1' '2' 'three']\n",
            "Data type: <U21\n",
            "\n",
            "Error: The 'out' kwarg is necessary. Use numpy.strings.multiply without it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at what happened. When we mixed integers and floats, NumPy converted everything to float64. This is usually fine.\n",
        "\n",
        "But when we mixed numbers with a string, NumPy converted everything to strings. The data type `<U21` means Unicode string with up to 21 characters. The numbers 1 and 2 became the strings '1' and '2'. When we tried to multiply by 2, NumPy threw an error because it cannot perform arithmetic on string arrays.\n",
        "\n",
        "NumPy did not throw an error when we created the array. It silently converted our data. The error only appeared when we tried to use the data for calculations."
      ],
      "metadata": {
        "id": "QuMRwFkNT4bM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.3 Why This Matters for Financial Calculations\n",
        "\n",
        "This silent conversion can corrupt your analysis in subtle ways. Imagine you are reading data from a CSV file and one of the values is accidentally formatted as text. Your entire array becomes strings, and your calculations produce nonsense."
      ],
      "metadata": {
        "id": "O3GMMPGZUJB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulating data read from a messy CSV file\n",
        "# One value has a dollar sign accidentally included\n",
        "messy_prices = np.array([100.50, 102.25, '$103.00', 101.75])\n",
        "print(\"Messy prices array:\", messy_prices)\n",
        "print(\"Data type:\", messy_prices.dtype)\n",
        "\n",
        "# Attempting to calculate returns will fail\n",
        "try:\n",
        "    returns = np.diff(messy_prices) / messy_prices[:-1]\n",
        "    print(\"Returns:\", returns)\n",
        "except TypeError as e:\n",
        "    print(\"\\nCannot calculate returns!\")\n",
        "    print(\"Error:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cicUm3E0Tzc4",
        "outputId": "b2417db0-cdf8-40d7-9269-fdcba9c0ea92"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Messy prices array: ['100.5' '102.25' '$103.00' '101.75']\n",
            "Data type: <U32\n",
            "\n",
            "Cannot calculate returns!\n",
            "Error: ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U32'), dtype('<U32')) -> None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One bad value turned the entire array into strings. The data type `<U32` means Unicode string with up to 32 characters. When we tried to calculate returns using `np.diff()`, NumPy could not perform the subtraction because you cannot subtract strings from each other.\n",
        "\n",
        "In practice, this is why data cleaning is so important. Before you convert a DataFrame column to a NumPy array, make sure the data types are correct. Use `.info()` on your DataFrame to check column types. Use `.astype()` to convert columns explicitly.\n",
        "\n",
        "The rule is simple: always check your data types before performing calculations. A few seconds of verification can save hours of debugging.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "zrP-DhChUO0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Array Attributes\n",
        "\n",
        "Just like DataFrames have attributes like `.shape` and `.index`, arrays have attributes that tell you about their structure. These are essential for debugging and for understanding what you are working with."
      ],
      "metadata": {
        "id": "yPdHeOc4UeMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create arrays of different dimensions\n",
        "array_1d = np.array([1, 2, 3, 4, 5])\n",
        "array_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "print(\"1D array:\", array_1d)\n",
        "print(\"Shape:\", array_1d.shape)\n",
        "\n",
        "print(\"\\n2D array:\")\n",
        "print(array_2d)\n",
        "print(\"Shape:\", array_2d.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrsSUrioUMEb",
        "outputId": "7cd61969-a1d9-4976-d7ae-d02f8d66ceff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1D array: [1 2 3 4 5]\n",
            "Shape: (5,)\n",
            "\n",
            "2D array:\n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "Shape: (2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `.shape` attribute returns a tuple describing the dimensions of the array.\n",
        "\n",
        "For the 1D array, the shape is `(5,)`. This means 5 elements in a single dimension. The trailing comma indicates it is a tuple with one element.\n",
        "\n",
        "For the 2D array, the shape is `(2, 3)`. This means 2 rows and 3 columns. The first number is always the number of rows, the second is the number of columns.\n",
        "\n",
        "Understanding shape is critical. When we get to machine learning, most errors you encounter will be shape mismatches. Get comfortable reading and interpreting shapes now."
      ],
      "metadata": {
        "id": "nazKHiYKUyDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.2 .dtype: Data Types and Precision\n",
        "\n",
        "The `.dtype` attribute tells you what kind of data the array holds. This is important for understanding memory usage and numerical precision."
      ],
      "metadata": {
        "id": "uAwpKZN1VyHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Different data types\n",
        "int_array = np.array([1, 2, 3])\n",
        "float_array = np.array([1.0, 2.0, 3.0])\n",
        "explicit_float32 = np.array([1.0, 2.0, 3.0], dtype=np.float32)\n",
        "\n",
        "print(\"Integer array dtype:\", int_array.dtype)\n",
        "print(\"Float array dtype:\", float_array.dtype)\n",
        "print(\"Float32 array dtype:\", explicit_float32.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB-7R3qqUtZ9",
        "outputId": "864821c1-642a-4e98-d735-8b13486e9058"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Integer array dtype: int64\n",
            "Float array dtype: float64\n",
            "Float32 array dtype: float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, NumPy creates 64-bit integers (`int64`) and 64-bit floats (`float64`). The 64 refers to the number of bits used to store each value. More bits means more precision but also more memory.\n",
        "\n",
        "For most financial work, `float64` is the right choice. It provides sufficient precision for price calculations and avoids rounding errors. You can specify a smaller type like `float32` to save memory when working with very large datasets, but this is rarely necessary.\n",
        "\n",
        "The key point is that you can check the type at any time with `.dtype`. If your calculations are producing unexpected results, this is one of the first things to check."
      ],
      "metadata": {
        "id": "tRdGczLLV8su"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.3 .ndim: Number of Dimensions\n",
        "\n",
        "The `.ndim` attribute tells you how many dimensions the array has. A 1D array has `ndim=1`, a 2D array has `ndim=2`, and so on."
      ],
      "metadata": {
        "id": "FTj8lpejWD4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array_1d = np.array([1, 2, 3, 4, 5])\n",
        "array_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "array_3d = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
        "\n",
        "print(\"1D array ndim:\", array_1d.ndim)\n",
        "print(\"2D array ndim:\", array_2d.ndim)\n",
        "print(\"3D array ndim:\", array_3d.ndim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVAJYpMuV0pl",
        "outputId": "774a4ddf-9813-4659-c7b5-cbc19deabab6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1D array ndim: 1\n",
            "2D array ndim: 2\n",
            "3D array ndim: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In financial work, you will mostly encounter 1D and 2D arrays. A 1D array might hold a series of returns. A 2D array might hold a matrix of returns for multiple assets over multiple time periods.\n",
        "\n",
        "3D arrays appear in more advanced applications, such as storing multiple covariance matrices over time or working with certain machine learning models. For now, just know that `.ndim` tells you the dimensionality at a glance."
      ],
      "metadata": {
        "id": "1gzWa8v2WKpw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.4 .size: Total Number of Elements\n",
        "\n",
        "The `.size` attribute returns the total number of elements in the array. For a 1D array, this is the same as the length. For a 2D array, it is the number of rows multiplied by the number of columns."
      ],
      "metadata": {
        "id": "W2dWNAdMV8N0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array_1d = np.array([1, 2, 3, 4, 5])\n",
        "array_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "print(\"1D array shape:\", array_1d.shape)\n",
        "print(\"1D array size:\", array_1d.size)\n",
        "\n",
        "print(\"\\n2D array shape:\", array_2d.shape)\n",
        "print(\"2D array size:\", array_2d.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiZdHWGpWbK3",
        "outputId": "9bb4568e-02cf-4546-f7bb-fcf82dbf3849"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1D array shape: (5,)\n",
            "1D array size: 5\n",
            "\n",
            "2D array shape: (2, 3)\n",
            "2D array size: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 1D array has shape `(5,)` and size 5. The 2D array has shape `(2, 3)` and size 6 (2 times 3).\n",
        "\n",
        "The `.size` attribute is useful when you need to know how many data points you are working with, regardless of how the array is shaped. This comes up when calculating statistics or when checking that two arrays have the same amount of data before reshaping.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "KqS5FWMjWgVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Indexing and Slicing Arrays\n",
        "\n",
        "Accessing elements in an array is similar to accessing elements in a Python list, but with more power. You can select individual elements, slice ranges, filter by condition, and select specific positions all in a single line."
      ],
      "metadata": {
        "id": "2uO4x9rQWp_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4.1 Basic Indexing (1D and 2D)\n",
        "\n",
        "Array indexing starts at 0, just like Python lists. For 2D arrays, you provide two indices: row first, then column."
      ],
      "metadata": {
        "id": "HVWEEteFWqq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1D array indexing\n",
        "prices = np.array([100, 102, 105, 103, 108])\n",
        "print(\"Prices:\", prices)\n",
        "print(\"First element (index 0):\", prices[0])\n",
        "print(\"Last element (index -1):\", prices[-1])\n",
        "print(\"Third element (index 2):\", prices[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtZKb9zWWekB",
        "outputId": "13cc8314-24b6-4003-8ab0-e87e97c759af"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prices: [100 102 105 103 108]\n",
            "First element (index 0): 100\n",
            "Last element (index -1): 108\n",
            "Third element (index 2): 105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Negative indexing works the same as in Python lists. Index -1 gives you the last element, -2 gives you the second to last, and so on.\n",
        "\n",
        "Now let's look at 2D indexing."
      ],
      "metadata": {
        "id": "Ctqv5Jd3W1gK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For 2D arrays, you specify the row index first, then the column index, separated by a comma."
      ],
      "metadata": {
        "id": "qGdtbT7LXBrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D array: rows are assets, columns are daily returns\n",
        "returns = np.array([\n",
        "    [0.01, 0.02, -0.01, 0.03],   # Asset 0\n",
        "    [0.02, -0.01, 0.02, 0.01],   # Asset 1\n",
        "    [-0.01, 0.03, 0.01, 0.02]    # Asset 2\n",
        "])\n",
        "\n",
        "print(\"Returns matrix:\")\n",
        "print(returns)\n",
        "print(\"\\nElement at row 0, column 1:\", returns[0, 1])\n",
        "print(\"Element at row 2, column 3:\", returns[2, 3])\n",
        "print(\"Entire row 1:\", returns[1])\n",
        "print(\"Entire column 2:\", returns[:, 2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RylxX_ukWyhO",
        "outputId": "c5df0408-06ad-44d0-f356-7ca978988afe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Returns matrix:\n",
            "[[ 0.01  0.02 -0.01  0.03]\n",
            " [ 0.02 -0.01  0.02  0.01]\n",
            " [-0.01  0.03  0.01  0.02]]\n",
            "\n",
            "Element at row 0, column 1: 0.02\n",
            "Element at row 2, column 3: 0.02\n",
            "Entire row 1: [ 0.02 -0.01  0.02  0.01]\n",
            "Entire column 2: [-0.01  0.02  0.01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The syntax `returns[0, 1]` gives you the element at row 0, column 1. This is the second return for the first asset.\n",
        "\n",
        "To select an entire row, you just provide the row index: `returns[1]` gives you all of Asset 1's returns.\n",
        "\n",
        "To select an entire column, you use a colon for the row index: `returns[:, 2]` gives you the third column, which is the return on day 2 for all assets. The colon means \"all rows\"."
      ],
      "metadata": {
        "id": "huprqOYHXE16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4.2 Slicing Ranges\n",
        "\n",
        "Slicing allows you to extract a portion of an array. The syntax is `start:stop:step`, where stop is excluded. This works the same as Python list slicing."
      ],
      "metadata": {
        "id": "sNQePchgXKUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prices = np.array([100, 102, 105, 103, 108, 110, 107])\n",
        "\n",
        "print(\"All prices:\", prices)\n",
        "print(\"First three (0:3):\", prices[0:3])\n",
        "print(\"From index 2 to end (2:):\", prices[2:])\n",
        "print(\"Up to index 4 (:4):\", prices[:4])\n",
        "print(\"Every other element (::2):\", prices[::2])\n",
        "print(\"Reversed (::-1):\", prices[::-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9QRizaeXDj_",
        "outputId": "36d82e0e-a910-4ea5-b277-96e23f79493e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All prices: [100 102 105 103 108 110 107]\n",
            "First three (0:3): [100 102 105]\n",
            "From index 2 to end (2:): [105 103 108 110 107]\n",
            "Up to index 4 (:4): [100 102 105 103]\n",
            "Every other element (::2): [100 105 108 107]\n",
            "Reversed (::-1): [107 110 108 103 105 102 100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key thing to remember is that the stop index is excluded. `prices[0:3]` gives you elements at indices 0, 1, and 2, not 3.\n",
        "\n",
        "Leaving out the start means \"from the beginning\". Leaving out the stop means \"to the end\". The step parameter lets you skip elements or reverse the array.\n",
        "\n",
        "These same slicing rules apply to 2D arrays. You can slice rows and columns independently."
      ],
      "metadata": {
        "id": "Wo14bt87XMyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4.3 Boolean Indexing (Filtering by Condition)\n",
        "\n",
        "Boolean indexing is one of the most powerful features of NumPy. You can filter an array by passing a condition, and NumPy returns only the elements that satisfy that condition."
      ],
      "metadata": {
        "id": "epk9Mq2QXTlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "returns = np.array([0.02, -0.01, 0.03, -0.02, 0.01, -0.03, 0.04])\n",
        "\n",
        "print(\"All returns:\", returns)\n",
        "\n",
        "# Create a boolean mask\n",
        "positive_mask = returns > 0\n",
        "print(\"\\nBoolean mask (returns > 0):\", positive_mask)\n",
        "\n",
        "# Apply the mask to filter\n",
        "positive_returns = returns[positive_mask]\n",
        "print(\"Positive returns only:\", positive_returns)\n",
        "\n",
        "# You can do this in one line\n",
        "negative_returns = returns[returns < 0]\n",
        "print(\"Negative returns only:\", negative_returns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prRKdxCoXMJ4",
        "outputId": "f6d3b414-e45e-48d5-aeeb-c8dc987692ea"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All returns: [ 0.02 -0.01  0.03 -0.02  0.01 -0.03  0.04]\n",
            "\n",
            "Boolean mask (returns > 0): [ True False  True False  True False  True]\n",
            "Positive returns only: [0.02 0.03 0.01 0.04]\n",
            "Negative returns only: [-0.01 -0.02 -0.03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you write `returns > 0`, NumPy creates a boolean array of the same shape with True where the condition is met and False where it is not.\n",
        "\n",
        "When you use this boolean array to index the original array, NumPy returns only the elements where the value is True.\n",
        "\n",
        "This is how you filter data in NumPy. Want only the days where the market was up? `returns[returns > 0]`. Want only the returns greater than 1%? `returns[returns > 0.01]`. This is cleaner and faster than writing loops."
      ],
      "metadata": {
        "id": "FwDIVPk9Xauk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4.4 Fancy Indexing (Selecting Specific Elements)\n",
        "\n",
        "Fancy indexing lets you select specific elements by passing a list of indices. This is useful when you want to extract elements that are not in a contiguous range."
      ],
      "metadata": {
        "id": "uTM2yGzaXhdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prices = np.array([100, 102, 105, 103, 108, 110, 107])\n",
        "\n",
        "print(\"All prices:\", prices)\n",
        "\n",
        "# Select specific indices\n",
        "selected_indices = [0, 2, 5]\n",
        "selected_prices = prices[selected_indices]\n",
        "print(\"\\nPrices at indices 0, 2, 5:\", selected_prices)\n",
        "\n",
        "# Useful for selecting specific assets from a returns matrix\n",
        "returns = np.array([\n",
        "    [0.01, 0.02, -0.01],   # Asset 0\n",
        "    [0.02, -0.01, 0.02],   # Asset 1\n",
        "    [-0.01, 0.03, 0.01],   # Asset 2\n",
        "    [0.03, 0.01, -0.02]    # Asset 3\n",
        "])\n",
        "\n",
        "# Select only assets 0 and 3\n",
        "selected_assets = returns[[0, 3]]\n",
        "print(\"\\nReturns for assets 0 and 3:\")\n",
        "print(selected_assets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OrmVDyBXV0j",
        "outputId": "8a71ec2d-6401-4e3f-fe6b-49092708ab7e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All prices: [100 102 105 103 108 110 107]\n",
            "\n",
            "Prices at indices 0, 2, 5: [100 105 110]\n",
            "\n",
            "Returns for assets 0 and 3:\n",
            "[[ 0.01  0.02 -0.01]\n",
            " [ 0.03  0.01 -0.02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fancy indexing is particularly useful when you need to select a subset of assets from a portfolio. If you have a universe of 100 stocks but only want to analyze 10 of them, you can pass a list of the 10 indices and extract just those rows.\n",
        "\n",
        "The order of the indices matters. NumPy returns the elements in the order you specify. This allows you to reorder elements by passing the indices in a different order.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "rta6mdQkXoz4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 What is Vectorization?\n",
        "\n",
        "Vectorization is the single most important concept in NumPy. It is the reason NumPy is fast. It is the reason we use NumPy instead of plain Python for numerical work.\n",
        "\n",
        "The idea is simple: instead of processing data one element at a time with a loop, you perform the operation on the entire array at once."
      ],
      "metadata": {
        "id": "7xqLkkdXYCJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1 Loops vs. Vectorized Operations\n",
        "\n",
        "Let's start with a simple example. Say you have an array of prices and you want to calculate the daily returns. The return for each day is the current price divided by the previous price, minus 1.\n",
        "\n",
        "Here is how you would do it with a loop."
      ],
      "metadata": {
        "id": "7IQ4qwlhYFpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prices = np.array([100, 102, 105, 103, 108, 110, 107, 112])\n",
        "\n",
        "# Calculate returns using a loop\n",
        "returns_loop = []\n",
        "for i in range(1, len(prices)):\n",
        "    daily_return = (prices[i] / prices[i-1]) - 1\n",
        "    returns_loop.append(daily_return)\n",
        "\n",
        "returns_loop = np.array(returns_loop)\n",
        "print(\"Returns (loop method):\")\n",
        "print(returns_loop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlmW0nOOXjSI",
        "outputId": "3343277f-0463-4bf2-e666-bd4b4913c3d7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Returns (loop method):\n",
            "[ 0.02        0.02941176 -0.01904762  0.04854369  0.01851852 -0.02727273\n",
            "  0.04672897]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This works, but it is slow. For each iteration, Python has to look up the values, perform the division, perform the subtraction, and append to a list. For a small array, you will not notice. For millions of data points, you will wait.\n",
        "\n",
        "Now let's do the same calculation with vectorization."
      ],
      "metadata": {
        "id": "Y6Q16EJVYKDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate returns using vectorization\n",
        "returns_vector = (prices[1:] / prices[:-1]) - 1\n",
        "\n",
        "print(\"Returns (vectorized method):\")\n",
        "print(returns_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZDoIq59YHXo",
        "outputId": "0368f029-bd52-4caa-c03c-598920d7d4ba"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Returns (vectorized method):\n",
            "[ 0.02        0.02941176 -0.01904762  0.04854369  0.01851852 -0.02727273\n",
            "  0.04672897]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One line. No loop. The result is identical.\n",
        "\n",
        "The syntax `prices[1:]` gives you all prices from index 1 to the end. The syntax `prices[:-1]` gives you all prices from the beginning to the second-to-last. NumPy divides these two arrays element by element, then subtracts 1 from every element.\n",
        "\n",
        "Notice that NumPy does not have a `.shift()` method like Pandas. When you need to compare an array to a lagged version of itself, you use slicing. This is a common pattern you will see throughout this notebook.\n",
        "\n",
        "This is vectorization: expressing operations on entire arrays rather than individual elements."
      ],
      "metadata": {
        "id": "cA1pUGDdYhRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.2 Why Vectorization is Faster\n",
        "\n",
        "The speed difference comes from how Python and NumPy work under the hood.\n",
        "\n",
        "When you write a Python loop, each iteration involves overhead: checking the loop condition, looking up variable names, type checking, and managing memory. This overhead happens for every single element.\n",
        "\n",
        "When you use a vectorized NumPy operation, the work is handed off to pre-compiled C code that operates on the entire array in one pass. The overhead happens once, not millions of times."
      ],
      "metadata": {
        "id": "fapK3D67Y25-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 The Speed Test\n",
        "\n",
        "Let's see the difference with a larger dataset. We will create an array of one million prices and time both methods."
      ],
      "metadata": {
        "id": "ZicodTGnY4oh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a large array of simulated prices\n",
        "np.random.seed(42)\n",
        "large_prices = 100 * np.cumprod(1 + np.random.normal(0.0001, 0.02, 1000000))\n",
        "\n",
        "print(f\"Array size: {len(large_prices):,} elements\")\n",
        "print(f\"First few prices: {large_prices[:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9dAVgakYSfJ",
        "outputId": "f16d1c58-7370-4ced-f8a9-c0bffcf699ae"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array size: 1,000,000 elements\n",
            "First few prices: [101.00342831 100.73422528 102.04918676 105.16787085 104.6858794 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have created one million simulated prices using random returns. Now let's time the loop method versus the vectorized method."
      ],
      "metadata": {
        "id": "TfYJ_vt8Y8ee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 Calculating Returns with a Loop"
      ],
      "metadata": {
        "id": "CV6hrk3UZCig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 1 -r 3\n",
        "\n",
        "returns_loop = []\n",
        "for i in range(1, len(large_prices)):\n",
        "    daily_return = (large_prices[i] / large_prices[i-1]) - 1\n",
        "    returns_loop.append(daily_return)\n",
        "returns_loop = np.array(returns_loop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYZXiI3aY6vp",
        "outputId": "255715c9-f3ec-4901-ee9c-8af96ec71114"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "563 ms  107 ms per loop (mean  std. dev. of 3 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `%%timeit` magic command runs the code multiple times and reports the average execution time. The `-n 1` flag means run the code once per loop, and `-r 3` means repeat the measurement 3 times.\n",
        "\n",
        "Note the time. Now let's see the vectorized version."
      ],
      "metadata": {
        "id": "LBtnP8i_ZH82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.2 Calculating Returns with Vectorization"
      ],
      "metadata": {
        "id": "KZQ1BzvHZO05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 1 -r 3\n",
        "\n",
        "returns_vector = (large_prices[1:] / large_prices[:-1]) - 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-K9yUs1ZEsJ",
        "outputId": "b4c0501f-cea7-4cbe-c302-c9607dcd061d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.87 ms  105 s per loop (mean  std. dev. of 3 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.3 The Difference\n",
        "\n",
        "The vectorized version is dramatically faster. On most machines, you will see a difference of 10x to 100x or more.\n",
        "\n",
        "This is not a small optimization. When you are backtesting a strategy over decades of minute-level data, or running thousands of Monte Carlo simulations, the difference between loops and vectorization is the difference between waiting seconds and waiting hours."
      ],
      "metadata": {
        "id": "tRLaNsPtZRvg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.4 When the Difference Matters\n",
        "\n",
        "For small datasets, the speed difference is negligible. If you are calculating returns on 252 trading days, both methods finish instantly. Use whichever is clearer to you.\n",
        "\n",
        "But the difference becomes critical in these situations:\n",
        "\n",
        "**Large datasets:** Years of tick data or minute-level data can contain millions or billions of rows. Vectorization is not optional.\n",
        "\n",
        "**Repeated calculations:** Backtesting often requires recalculating signals and returns thousands of times across different parameter combinations. A 50x speedup per calculation compounds quickly.\n",
        "\n",
        "**Real-time systems:** If your trading system needs to process data and generate signals within milliseconds, every operation matters.\n",
        "\n",
        "**Monte Carlo simulations:** Running 10,000 simulations of portfolio performance requires processing the same calculations 10,000 times. Vectorization makes this feasible.\n",
        "\n",
        "The rule is simple: learn to think in arrays, not loops. When you catch yourself writing a for loop to process numerical data, pause and ask if there is a vectorized way to do it. There usually is.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "8YGcbWi8Zdio"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Common Vectorized Operations\n",
        "\n",
        "Now that you understand why vectorization matters, let's look at the operations you will use most often."
      ],
      "metadata": {
        "id": "qlj_8InucRwA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.1 Element-wise Arithmetic\n",
        "\n",
        "When you perform arithmetic on arrays, NumPy applies the operation to each element. If you operate on two arrays of the same shape, NumPy pairs up the elements and applies the operation to each pair."
      ],
      "metadata": {
        "id": "1m3A0ePacUZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prices = np.array([100, 102, 105, 103, 108])\n",
        "shares = np.array([10, 20, 15, 25, 10])\n",
        "\n",
        "# Multiply each price by the corresponding number of shares\n",
        "position_values = prices * shares\n",
        "print(\"Prices:\", prices)\n",
        "print(\"Shares:\", shares)\n",
        "print(\"Position values:\", position_values)\n",
        "\n",
        "# Add a fixed cost to each price\n",
        "prices_with_fee = prices + 0.50\n",
        "print(\"\\nPrices with $0.50 fee:\", prices_with_fee)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiw-j7ixZP5q",
        "outputId": "e6f2d36b-5d56-4995-b7f7-d4c809b5a490"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prices: [100 102 105 103 108]\n",
            "Shares: [10 20 15 25 10]\n",
            "Position values: [1000 2040 1575 2575 1080]\n",
            "\n",
            "Prices with $0.50 fee: [100.5 102.5 105.5 103.5 108.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The multiplication `prices * shares` does not multiply all prices by all shares. It multiplies the first price by the first share count, the second price by the second share count, and so on. This is element-wise operation.\n",
        "\n",
        "When you add a single number to an array, NumPy adds that number to every element. This is called broadcasting, which we will cover in detail later."
      ],
      "metadata": {
        "id": "8kMbQfmzcf7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.2 Aggregations: np.sum(), np.mean(), np.std()\n",
        "\n",
        "Aggregation functions reduce an array to a single value. These are the workhorses of financial calculations."
      ],
      "metadata": {
        "id": "6bfnvISicoJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "returns = np.array([0.02, -0.01, 0.03, -0.02, 0.01, 0.04, -0.01, 0.02])\n",
        "\n",
        "print(\"Returns:\", returns)\n",
        "print(\"\\nTotal return (sum):\", np.sum(returns))\n",
        "print(\"Average return (mean):\", np.mean(returns))\n",
        "print(\"Volatility (std):\", np.std(returns))\n",
        "print(\"Min return:\", np.min(returns))\n",
        "print(\"Max return:\", np.max(returns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41vmjlAncXF8",
        "outputId": "cd7e4591-ccb1-4fba-952a-66c13bbb4eba"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Returns: [ 0.02 -0.01  0.03 -0.02  0.01  0.04 -0.01  0.02]\n",
            "\n",
            "Total return (sum): 0.08\n",
            "Average return (mean): 0.01\n",
            "Volatility (std): 0.02\n",
            "Min return: -0.02\n",
            "Max return: 0.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These functions work on the entire array by default. The sum of returns gives you the total return (though remember from Notebook 2.1, you should use `.cumprod()` for compounding). The mean gives you the average return. The standard deviation gives you volatility.\n",
        "\n",
        "For 2D arrays, you can specify an axis to aggregate along rows or columns."
      ],
      "metadata": {
        "id": "lWAmiWtFctgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns matrix: rows are assets, columns are days\n",
        "returns_matrix = np.array([\n",
        "    [0.01, 0.02, -0.01, 0.03],   # Asset 0\n",
        "    [0.02, -0.01, 0.02, 0.01],   # Asset 1\n",
        "    [-0.01, 0.03, 0.01, 0.02]    # Asset 2\n",
        "])\n",
        "\n",
        "print(\"Returns matrix:\")\n",
        "print(returns_matrix)\n",
        "\n",
        "print(\"\\nMean return per asset (axis=1):\", np.mean(returns_matrix, axis=1))\n",
        "print(\"Mean return per day (axis=0):\", np.mean(returns_matrix, axis=0))\n",
        "print(\"Overall mean:\", np.mean(returns_matrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9vs15Nbcqfv",
        "outputId": "aa5304fa-3e2a-45d5-bb8d-10a63ae0d217"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Returns matrix:\n",
            "[[ 0.01  0.02 -0.01  0.03]\n",
            " [ 0.02 -0.01  0.02  0.01]\n",
            " [-0.01  0.03  0.01  0.02]]\n",
            "\n",
            "Mean return per asset (axis=1): [0.0125 0.01   0.0125]\n",
            "Mean return per day (axis=0): [0.00666667 0.01333333 0.00666667 0.02      ]\n",
            "Overall mean: 0.011666666666666665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `axis` parameter controls the direction of the aggregation.\n",
        "\n",
        "`axis=1` aggregates across columns, giving you one value per row. This is the mean return for each asset across all days.\n",
        "\n",
        "`axis=0` aggregates across rows, giving you one value per column. This is the mean return for each day across all assets.\n",
        "\n",
        "With no axis specified, the function aggregates the entire array into a single value.\n",
        "\n",
        "The axis numbering can be confusing at first. Think of it this way: `axis=0` collapses the rows, `axis=1` collapses the columns."
      ],
      "metadata": {
        "id": "ye55XVDzc50o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.3 Logical Operations: np.where(), np.any(), np.all()\n",
        "\n",
        "Logical operations let you make decisions based on array values. These are essential for creating trading signals and filtering data."
      ],
      "metadata": {
        "id": "M-R2r9kDdAHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "returns = np.array([0.02, -0.01, 0.03, -0.02, 0.01, -0.03, 0.04])\n",
        "\n",
        "# np.where: if condition is true, use first value; otherwise use second value\n",
        "signals = np.where(returns > 0, 1, -1)\n",
        "print(\"Returns:\", returns)\n",
        "print(\"Signals (1 if positive, -1 if negative):\", signals)\n",
        "\n",
        "# Create a more nuanced signal\n",
        "# 1 if return > 1%, -1 if return < -1%, 0 otherwise\n",
        "signals_nuanced = np.where(returns > 0.01, 1, np.where(returns < -0.01, -1, 0))\n",
        "print(\"\\nNuanced signals:\", signals_nuanced)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDUbQZPQc0sS",
        "outputId": "cd703ad8-d444-43ef-9281-4054b5d8067d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Returns: [ 0.02 -0.01  0.03 -0.02  0.01 -0.03  0.04]\n",
            "Signals (1 if positive, -1 if negative): [ 1 -1  1 -1  1 -1  1]\n",
            "\n",
            "Nuanced signals: [ 1  0  1 -1  0 -1  1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `np.where()` function is like an if-else statement for arrays. The first argument is the condition, the second is the value to use when true, and the third is the value to use when false.\n",
        "\n",
        "You can nest `np.where()` calls to create more complex logic, as shown in the nuanced signal example. This is how you build trading rules without writing loops."
      ],
      "metadata": {
        "id": "_uSFJrpMdEVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "returns = np.array([0.02, -0.01, 0.03, -0.02, 0.01, -0.03, 0.04])\n",
        "\n",
        "# np.any: True if ANY element meets the condition\n",
        "has_large_loss = np.any(returns < -0.02)\n",
        "print(\"Returns:\", returns)\n",
        "print(\"Any return below -2%?\", has_large_loss)\n",
        "\n",
        "# np.all: True if ALL elements meet the condition\n",
        "all_positive = np.all(returns > 0)\n",
        "print(\"All returns positive?\", all_positive)\n",
        "\n",
        "# Practical example: check if a portfolio is valid (weights sum to 1)\n",
        "weights = np.array([0.25, 0.25, 0.30, 0.20])\n",
        "is_valid = np.isclose(np.sum(weights), 1.0)\n",
        "print(\"\\nPortfolio weights:\", weights)\n",
        "print(\"Weights sum to 1?\", is_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWpS-DuTenMs",
        "outputId": "75ed9eab-e033-4d84-9973-a078cdc07eb5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Returns: [ 0.02 -0.01  0.03 -0.02  0.01 -0.03  0.04]\n",
            "Any return below -2%? True\n",
            "All returns positive? False\n",
            "\n",
            "Portfolio weights: [0.25 0.25 0.3  0.2 ]\n",
            "Weights sum to 1? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `np.any()` function returns True if at least one element satisfies the condition. Use this to check for exceptions or outliers. Did any day have a loss greater than 5%? Did any asset hit its stop loss?\n",
        "\n",
        "The `np.all()` function returns True only if every element satisfies the condition. Use this to validate data. Are all weights positive? Are all prices above zero?\n",
        "\n",
        "The `np.isclose()` function checks if two values are approximately equal, accounting for floating point precision. This is safer than using `==` when comparing floats (and this is incredibly useful for trading systems that have parameter thresholds!)."
      ],
      "metadata": {
        "id": "IR9cUPPkemsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.4 Practical Example: Calculating Portfolio Returns\n",
        "\n",
        "Let's bring these operations together with a practical example. You have a portfolio of three assets with known weights. You want to calculate the portfolio return for each day."
      ],
      "metadata": {
        "id": "zFi9dn-te6Bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Asset returns for 5 days (rows are assets, columns are days)\n",
        "asset_returns = np.array([\n",
        "    [0.01, 0.02, -0.01, 0.03, 0.01],   # Stock A\n",
        "    [0.02, -0.01, 0.02, 0.01, -0.02],  # Stock B\n",
        "    [-0.01, 0.03, 0.01, 0.02, 0.01]    # Stock C\n",
        "])\n",
        "\n",
        "# Portfolio weights\n",
        "weights = np.array([0.5, 0.3, 0.2])\n",
        "\n",
        "# Calculate portfolio return for each day\n",
        "# Matrix multiplication: weights (1x3) dot returns (3x5) = (1x5)\n",
        "portfolio_returns = np.dot(weights, asset_returns)\n",
        "\n",
        "print(\"Asset returns:\")\n",
        "print(asset_returns)\n",
        "print(\"\\nWeights:\", weights)\n",
        "print(\"\\nPortfolio returns per day:\", portfolio_returns)\n",
        "print(\"Total portfolio return:\", np.sum(portfolio_returns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q77O71w0dCGD",
        "outputId": "17e012f4-ba26-45e4-98e2-237f59b60fae"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asset returns:\n",
            "[[ 0.01  0.02 -0.01  0.03  0.01]\n",
            " [ 0.02 -0.01  0.02  0.01 -0.02]\n",
            " [-0.01  0.03  0.01  0.02  0.01]]\n",
            "\n",
            "Weights: [0.5 0.3 0.2]\n",
            "\n",
            "Portfolio returns per day: [0.009 0.013 0.003 0.022 0.001]\n",
            "Total portfolio return: 0.048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `np.dot()` function performs the dot product, which is exactly what we need for portfolio return calculation. Each day's portfolio return is the weighted sum of the individual asset returns.\n",
        "\n",
        "For day 1: (0.5  0.01) + (0.3  0.02) + (0.2  -0.01) = 0.009\n",
        "\n",
        "This single line replaces what would otherwise be nested loops. The calculation is clear, concise, and fast.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "tPCx1yZgfHmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.5 The Same Calculation in Pandas\n",
        "\n",
        "Let's do the same portfolio return calculation using Pandas. This will show you the trade-off between the two approaches."
      ],
      "metadata": {
        "id": "KqsKVz8OgjCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame with the same data\n",
        "dates = pd.date_range('2024-07-01', periods=5)\n",
        "df_returns = pd.DataFrame({\n",
        "    'Stock_A': [0.01, 0.02, -0.01, 0.03, 0.01],\n",
        "    'Stock_B': [0.02, -0.01, 0.02, 0.01, -0.02],\n",
        "    'Stock_C': [-0.01, 0.03, 0.01, 0.02, 0.01]\n",
        "}, index=dates)\n",
        "\n",
        "# Weights as a Series\n",
        "weights_series = pd.Series({'Stock_A': 0.5, 'Stock_B': 0.3, 'Stock_C': 0.2})\n",
        "\n",
        "# Calculate portfolio returns\n",
        "portfolio_returns_pandas = df_returns.dot(weights_series)\n",
        "\n",
        "print(\"Returns DataFrame:\")\n",
        "print(df_returns)\n",
        "print(\"\\nWeights:\")\n",
        "print(weights_series)\n",
        "print(\"\\nPortfolio returns:\")\n",
        "print(portfolio_returns_pandas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fare2InFfDq2",
        "outputId": "c2c0dab4-3346-420c-b816-8e5b82b6effc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Returns DataFrame:\n",
            "            Stock_A  Stock_B  Stock_C\n",
            "2024-07-01     0.01     0.02    -0.01\n",
            "2024-07-02     0.02    -0.01     0.03\n",
            "2024-07-03    -0.01     0.02     0.01\n",
            "2024-07-04     0.03     0.01     0.02\n",
            "2024-07-05     0.01    -0.02     0.01\n",
            "\n",
            "Weights:\n",
            "Stock_A    0.5\n",
            "Stock_B    0.3\n",
            "Stock_C    0.2\n",
            "dtype: float64\n",
            "\n",
            "Portfolio returns:\n",
            "2024-07-01    0.009\n",
            "2024-07-02    0.013\n",
            "2024-07-03    0.003\n",
            "2024-07-04    0.022\n",
            "2024-07-05    0.001\n",
            "Freq: D, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Pandas version uses the same `.dot()` method, but notice what you get in return. The result is a Series with the date index preserved. You can immediately see which return belongs to which day.\n",
        "\n",
        "With the NumPy version, you get a raw array: `[0.009, 0.015, 0.002, 0.021, -0.001]`. You have to remember which position corresponds to which date.\n",
        "\n",
        "This is the core trade-off. Pandas keeps your labels. NumPy gives you speed."
      ],
      "metadata": {
        "id": "AbKQhunOgsKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.6 When to Use Pandas vs NumPy\n",
        "\n",
        "**Use Pandas when:**\n",
        "\n",
        "- You are building and debugging your strategy. The labels make it easier to verify your calculations.\n",
        "- You need to combine portfolio returns with other time series data. Everything stays aligned by date.\n",
        "- You are working with a single backtest and speed is not critical.\n",
        "- You want to export results to CSV or visualize them. Pandas integrates smoothly with these workflows.\n",
        "\n",
        "**Use NumPy when:**\n",
        "\n",
        "- You are running many simulations or optimizations. The speed difference compounds.\n",
        "- You are passing data to machine learning libraries. They expect arrays.\n",
        "- You are doing portfolio optimization. The matrix math is cleaner in NumPy.\n",
        "- You have already cleaned and validated your data and no longer need the safety of labels.\n",
        "\n",
        "In practice, most quants work in Pandas during the research and d"
      ],
      "metadata": {
        "id": "ml2DMcN3g6FD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create larger datasets for timing comparison\n",
        "np.random.seed(42)\n",
        "n_assets = 100\n",
        "n_days = 10000\n",
        "\n",
        "# NumPy array\n",
        "large_returns_array = np.random.normal(0.0005, 0.02, (n_assets, n_days))\n",
        "large_weights_array = np.random.random(n_assets)\n",
        "large_weights_array = large_weights_array / large_weights_array.sum()\n",
        "\n",
        "# Pandas DataFrame\n",
        "dates = pd.date_range('2000-01-01', periods=n_days)\n",
        "columns = [f'Asset_{i}' for i in range(n_assets)]\n",
        "large_returns_df = pd.DataFrame(large_returns_array.T, index=dates, columns=columns)\n",
        "large_weights_series = pd.Series(large_weights_array, index=columns)\n",
        "\n",
        "print(f\"Dataset size: {n_assets} assets  {n_days:,} days\")\n",
        "print(f\"Total calculations per backtest: {n_assets * n_days:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC-G3F45gt2h",
        "outputId": "62e41b8e-2f0a-4b2a-8e2b-70a7178e9cb8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 100 assets  10,000 days\n",
            "Total calculations per backtest: 1,000,000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a realistic sized dataset: 100 assets over 10,000 trading days (about 40 years of daily data). Let's time both approaches."
      ],
      "metadata": {
        "id": "9z9dbbzNg-7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 100 -r 3\n",
        "\n",
        "portfolio_returns_np = np.dot(large_weights_array, large_returns_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p5RBDZPg9Cr",
        "outputId": "04887488-3182-4c12-9671-d47aeb32203e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "408 s  63.5 s per loop (mean  std. dev. of 3 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the time for the NumPy version. Now let's time the Pandas version."
      ],
      "metadata": {
        "id": "t5H9feENha7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 100 -r 3\n",
        "\n",
        "portfolio_returns_pd = large_returns_df.dot(large_weights_series)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqDp0Rt2hZ0A",
        "outputId": "94c2a59c-521f-484a-ef13-010bae142971"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 4.26 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "2.07 ms  1.09 ms per loop (mean  std. dev. of 3 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results tell the story:\n",
        "\n",
        "- NumPy: 408 s (microseconds) per loop\n",
        "- Pandas: 2.07 ms (milliseconds) per loop\n",
        "\n",
        "NumPy is about 5 times faster for this calculation. The Pandas version has overhead from maintaining the index alignment and returning a labeled Series.\n",
        "\n",
        "For a single backtest, 2 milliseconds is nothing. But consider what happens when you need to run this calculation repeatedly.\n",
        "\n",
        "If you are optimizing portfolio weights across 10,000 different weight combinations, that 1.6 millisecond difference becomes 16 seconds of extra waiting. If you are running a Monte Carlo simulation with 100,000 paths, it becomes nearly 3 minutes.\n",
        "\n",
        "This is why production systems and optimization routines typically work with NumPy arrays, even though the research was done in Pandas.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "WeFhmOEhhl2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 The Shape Lab: Preparing for Machine Learning\n",
        "\n",
        "This section will save you hours of frustration. When you start working with machine learning libraries like scikit-learn, you will encounter shape errors. They are cryptic. They are annoying. And they are almost always caused by the same few problems.\n",
        "\n",
        "The Shape Lab will teach you to diagnose and fix these problems before they derail your workflow."
      ],
      "metadata": {
        "id": "NGcxG8rViG9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.1 The Bridge: From Pandas to NumPy\n",
        "\n",
        "Machine learning libraries expect NumPy arrays, not DataFrames. Before you can train a model, you need to extract your data from Pandas and convert it to the right format.\n",
        "\n",
        "The two methods for this are `.values` and `.to_numpy()`. They do the same thing."
      ],
      "metadata": {
        "id": "k7wb7pr9iJXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a simple DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Returns': [0.01, 0.02, -0.01, 0.03, 0.02],\n",
        "    'Volume': [1000, 1500, 1200, 1800, 1600],\n",
        "    'Volatility': [0.15, 0.18, 0.22, 0.19, 0.17]\n",
        "}, index=pd.date_range('2024-07-01', periods=5))\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Extract using .values\n",
        "array_values = df['Returns'].values\n",
        "print(\"\\nUsing .values:\", array_values)\n",
        "print(\"Type:\", type(array_values))\n",
        "\n",
        "# Extract using .to_numpy()\n",
        "array_tonumpy = df['Returns'].to_numpy()\n",
        "print(\"\\nUsing .to_numpy():\", array_tonumpy)\n",
        "print(\"Type:\", type(array_tonumpy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrZXuNGKhc4X",
        "outputId": "037b15be-58dc-4699-e25a-afd05006c502"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "            Returns  Volume  Volatility\n",
            "2024-07-01     0.01    1000        0.15\n",
            "2024-07-02     0.02    1500        0.18\n",
            "2024-07-03    -0.01    1200        0.22\n",
            "2024-07-04     0.03    1800        0.19\n",
            "2024-07-05     0.02    1600        0.17\n",
            "\n",
            "Using .values: [ 0.01  0.02 -0.01  0.03  0.02]\n",
            "Type: <class 'numpy.ndarray'>\n",
            "\n",
            "Using .to_numpy(): [ 0.01  0.02 -0.01  0.03  0.02]\n",
            "Type: <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both methods return a NumPy array. The `.to_numpy()` method is the modern, recommended approach. The `.values` attribute is older but still widely used.\n",
        "\n",
        "Notice that when you extract a single column, the labels disappear. You get a raw array of numbers. The date index is gone."
      ],
      "metadata": {
        "id": "wSfrEHryiNWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.2 When You Need to Cross the Bridge\n",
        "\n",
        "You will need to extract arrays from DataFrames in these situations:\n",
        "\n",
        "- Feeding features into scikit-learn models (LinearRegression, RandomForest, etc.)\n",
        "- Performing matrix operations for portfolio optimization\n",
        "- Passing data to other numerical libraries like SciPy or TensorFlow\n",
        "- When you need maximum speed and have finished your data cleaning\n",
        "\n",
        "Let's see what this looks like with a typical machine learning setup."
      ],
      "metadata": {
        "id": "WUBin-lLiSIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Typical ML setup: features and target\n",
        "df = pd.DataFrame({\n",
        "    'Momentum': [0.05, 0.02, -0.03, 0.04, 0.01],\n",
        "    'Volatility': [0.15, 0.18, 0.22, 0.19, 0.17],\n",
        "    'Volume_Change': [0.10, -0.05, 0.15, 0.08, -0.02],\n",
        "    'Next_Return': [0.02, -0.01, 0.03, 0.01, 0.02]\n",
        "}, index=pd.date_range('2024-07-01', periods=5))\n",
        "\n",
        "# Features (X) and target (y)\n",
        "feature_columns = ['Momentum', 'Volatility', 'Volume_Change']\n",
        "target_column = 'Next_Return'\n",
        "\n",
        "X = df[feature_columns].to_numpy()\n",
        "y = df[target_column].to_numpy()\n",
        "\n",
        "print(\"Features (X):\")\n",
        "print(X)\n",
        "print(\"\\nShape of X:\", X.shape)\n",
        "\n",
        "print(\"\\nTarget (y):\")\n",
        "print(y)\n",
        "print(\"Shape of y:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bK7UGRziLJT",
        "outputId": "7b39170f-c8d3-4060-cd41-7429bd099c48"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features (X):\n",
            "[[ 0.05  0.15  0.1 ]\n",
            " [ 0.02  0.18 -0.05]\n",
            " [-0.03  0.22  0.15]\n",
            " [ 0.04  0.19  0.08]\n",
            " [ 0.01  0.17 -0.02]]\n",
            "\n",
            "Shape of X: (5, 3)\n",
            "\n",
            "Target (y):\n",
            "[ 0.02 -0.01  0.03  0.01  0.02]\n",
            "Shape of y: (5,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the standard pattern. Your features (X) are a 2D array where each row is an observation and each column is a feature. Your target (y) is a 1D array of the values you are trying to predict.\n",
        "\n",
        "Look at the shapes:\n",
        "- X has shape `(5, 3)`: 5 observations, 3 features\n",
        "- y has shape `(5,)`: 5 observations\n",
        "\n",
        "This is where shape problems begin. That `(5,)` shape for y is going to cause issues with certain operations."
      ],
      "metadata": {
        "id": "FCeIY8OziW46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Understanding Shape\n",
        "\n",
        "Shape is the source of most errors when working with NumPy and machine learning. Understanding the difference between 1D and 2D arrays will save you countless hours of debugging."
      ],
      "metadata": {
        "id": "dkGqrWOujB0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.1 1D Arrays: Shape (n,)\n",
        "\n",
        "A 1D array is a simple sequence of values. When you extract a single column from a DataFrame, you get a 1D array. When you create an array from a flat list, you get a 1D array."
      ],
      "metadata": {
        "id": "HwCHF_E3jEyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating 1D arrays\n",
        "array_1d = np.array([1, 2, 3, 4, 5])\n",
        "\n",
        "print(\"1D Array:\", array_1d)\n",
        "print(\"Shape:\", array_1d.shape)\n",
        "print(\"Number of dimensions:\", array_1d.ndim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAPLiCajiUAS",
        "outputId": "1977c455-4c24-4991-87b5-894dc85ccb7f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1D Array: [1 2 3 4 5]\n",
            "Shape: (5,)\n",
            "Number of dimensions: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape `(5,)` tells you this is a 1D array with 5 elements. The trailing comma indicates a tuple with a single element. This is not the same as `(5, 1)`, which would be a 2D array. This distinction matters enormously."
      ],
      "metadata": {
        "id": "Z5DsnmIsjHm6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.2 2D Arrays: Shape (n, m)\n",
        "\n",
        "A 2D array has rows and columns. When you extract multiple columns from a DataFrame, you get a 2D array. When you create an array from nested lists, you get a 2D array."
      ],
      "metadata": {
        "id": "Eor-U9NMjUKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating 2D arrays\n",
        "array_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "print(\"2D Array:\")\n",
        "print(array_2d)\n",
        "print(\"\\nShape:\", array_2d.shape)\n",
        "print(\"Number of dimensions:\", array_2d.ndim)\n",
        "\n",
        "# A 2D array with only one column\n",
        "single_column_2d = np.array([[1], [2], [3], [4], [5]])\n",
        "\n",
        "print(\"\\nSingle column 2D array:\")\n",
        "print(single_column_2d)\n",
        "print(\"Shape:\", single_column_2d.shape)\n",
        "print(\"Number of dimensions:\", single_column_2d.ndim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB6DoOb8jGF7",
        "outputId": "495172d5-21b9-4df3-d516-e4b366a02f36"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2D Array:\n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "\n",
            "Shape: (2, 3)\n",
            "Number of dimensions: 2\n",
            "\n",
            "Single column 2D array:\n",
            "[[1]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [5]]\n",
            "Shape: (5, 1)\n",
            "Number of dimensions: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first array has shape `(2, 3)`: 2 rows, 3 columns.\n",
        "\n",
        "The second array has shape `(5, 1)`: 5 rows, 1 column. This is still a 2D array, even though there is only one column. It has two dimensions, and `ndim` confirms this.\n",
        "\n",
        "Compare this to our 1D array with shape `(5,)`. Both contain 5 elements. Both could represent the same data. But they are not interchangeable. Many functions treat them differently."
      ],
      "metadata": {
        "id": "XldFYXazjXp4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.3 Why Machine Learning Models Expect 2D Input\n",
        "\n",
        "Scikit-learn and most machine learning libraries expect your features (X) to be a 2D array. Each row is an observation. Each column is a feature. Even if you have only one feature, the library still expects a 2D array with shape `(n_samples, 1)`, not a 1D array with shape `(n_samples,)`.\n",
        "\n",
        "This is a design decision that makes the libraries consistent. Every model works the same way regardless of whether you have 1 feature or 100 features. But it means you need to reshape your data when you have a single feature."
      ],
      "metadata": {
        "id": "Sqfuw0sgjgw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulating a common scenario: predicting returns from a single feature\n",
        "momentum = np.array([0.05, 0.02, -0.03, 0.04, 0.01])\n",
        "next_returns = np.array([0.02, -0.01, 0.03, 0.01, 0.02])\n",
        "\n",
        "print(\"Momentum (our single feature):\", momentum)\n",
        "print(\"Shape:\", momentum.shape)\n",
        "\n",
        "print(\"\\nNext returns (our target):\", next_returns)\n",
        "print(\"Shape:\", next_returns.shape)\n",
        "\n",
        "print(\"\\nBoth are 1D arrays. If we try to use momentum as X in scikit-learn, we will get an error.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XwpI-t0jV4E",
        "outputId": "799499e7-8120-40e8-c40a-8dbb75d2a7cb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Momentum (our single feature): [ 0.05  0.02 -0.03  0.04  0.01]\n",
            "Shape: (5,)\n",
            "\n",
            "Next returns (our target): [ 0.02 -0.01  0.03  0.01  0.02]\n",
            "Shape: (5,)\n",
            "\n",
            "Both are 1D arrays. If we try to use momentum as X in scikit-learn, we will get an error.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have one feature (momentum) and one target (next returns). Both are 1D arrays. The target can stay as a 1D array. But the feature must be reshaped to 2D before scikit-learn will accept it.\n",
        "\n",
        "Let's see what happens when we try to use this data without reshaping.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "tA5rmF64joJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 The Shape Trap\n",
        "\n",
        "This section shows you the exact error you will encounter and how to fix it. We will deliberately trigger the error so you recognize it when it happens in your own work."
      ],
      "metadata": {
        "id": "dEahURXmkKWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.1 Why (n,) is Not the Same as (n, 1)\n",
        "\n",
        "Both `(n,)` and `(n, 1)` contain n elements. But they are fundamentally different structures. A 1D array has no concept of rows or columns. A 2D array with shape `(n, 1)` has n rows and 1 column."
      ],
      "metadata": {
        "id": "ftX_8CWTkMZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array_1d = np.array([1, 2, 3, 4, 5])\n",
        "array_2d = np.array([[1], [2], [3], [4], [5]])\n",
        "\n",
        "print(\"1D array:\")\n",
        "print(array_1d)\n",
        "print(\"Shape:\", array_1d.shape)\n",
        "\n",
        "print(\"\\n2D array:\")\n",
        "print(array_2d)\n",
        "print(\"Shape:\", array_2d.shape)\n",
        "\n",
        "print(\"\\nAre they equal?\", np.array_equal(array_1d, array_2d))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5X2mglqjjtw",
        "outputId": "a2e85bd2-17e6-45f8-fc18-798e4fa5c3c7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1D array:\n",
            "[1 2 3 4 5]\n",
            "Shape: (5,)\n",
            "\n",
            "2D array:\n",
            "[[1]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [5]]\n",
            "Shape: (5, 1)\n",
            "\n",
            "Are they equal? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "They contain the same values but they are not equal. NumPy considers them different objects because their shapes do not match.\n",
        "\n",
        "This is why machine learning libraries reject 1D arrays for features. They are checking shape, not just values."
      ],
      "metadata": {
        "id": "Njie5KGXkQsg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.2 The Sklearn Error You Will See\n",
        "\n",
        "Let's trigger the error. We will try to fit a simple linear regression using our 1D momentum array as the feature."
      ],
      "metadata": {
        "id": "f_Vw3A_3kX8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Our data (both 1D)\n",
        "momentum = np.array([0.05, 0.02, -0.03, 0.04, 0.01])\n",
        "next_returns = np.array([0.02, -0.01, 0.03, 0.01, 0.02])\n",
        "\n",
        "# Try to fit a model\n",
        "model = LinearRegression()\n",
        "\n",
        "try:\n",
        "    model.fit(momentum, next_returns)\n",
        "except ValueError as e:\n",
        "    print(\"Error!\")\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc3YVQ6vkPIX",
        "outputId": "abe87c3e-939c-4dd9-c8c6-ada89726e155"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error!\n",
            "Expected 2D array, got 1D array instead:\n",
            "array=[ 0.05  0.02 -0.03  0.04  0.01].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There it is. This is the error message you will see over and over until you internalize the shape rules.\n",
        "\n",
        "The message is actually helpful. It tells you exactly what went wrong: scikit-learn expected a 2D array but got a 1D array. It even tells you how to fix it: use `.reshape(-1, 1)` for a single feature.\n",
        "\n",
        "Let's break down what that means."
      ],
      "metadata": {
        "id": "9p_GltyCkgo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.3 Diagnosing Shape Mismatches\n",
        "\n",
        "When you encounter a shape error, the first step is always to check the shape of your data. Print the shape before passing data to any function. This simple habit will save you hours."
      ],
      "metadata": {
        "id": "kLwJMKkCk0f6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Always check shapes before fitting a model\n",
        "print(\"Feature shape:\", momentum.shape)\n",
        "print(\"Feature ndim:\", momentum.ndim)\n",
        "\n",
        "print(\"\\nTarget shape:\", next_returns.shape)\n",
        "print(\"Target ndim:\", next_returns.ndim)\n",
        "\n",
        "print(\"\\nProblem: Feature is 1D. Sklearn expects 2D for features.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffllhjX3kbnp",
        "outputId": "ed1e56af-7bb1-4926-ca38-aea7e20c8503"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature shape: (5,)\n",
            "Feature ndim: 1\n",
            "\n",
            "Target shape: (5,)\n",
            "Target ndim: 1\n",
            "\n",
            "Problem: Feature is 1D. Sklearn expects 2D for features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The diagnosis is clear. Our feature array has shape `(5,)` with 1 dimension. Scikit-learn expects shape `(5, 1)` with 2 dimensions.\n",
        "\n",
        "The target array is fine. Scikit-learn accepts 1D arrays for the target variable. It is only the feature matrix that must be 2D.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "rhcZL0yZk5hx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 The Fix: Reshaping Arrays\n",
        "\n",
        "Now that you understand the problem, the fix is straightforward. NumPy provides several methods to change the shape of an array without changing its data."
      ],
      "metadata": {
        "id": "nSl4Y1xOk9En"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4.1 .reshape(): Changing Dimensions\n",
        "\n",
        "The `.reshape()` method returns a new array with the same data but a different shape. The total number of elements must stay the same."
      ],
      "metadata": {
        "id": "HfX1vUEGlA4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array_1d = np.array([1, 2, 3, 4, 5, 6])\n",
        "\n",
        "print(\"Original 1D array:\", array_1d)\n",
        "print(\"Shape:\", array_1d.shape)\n",
        "\n",
        "# Reshape to 2D: 2 rows, 3 columns\n",
        "array_2x3 = array_1d.reshape(2, 3)\n",
        "print(\"\\nReshaped to (2, 3):\")\n",
        "print(array_2x3)\n",
        "print(\"Shape:\", array_2x3.shape)\n",
        "\n",
        "# Reshape to 2D: 3 rows, 2 columns\n",
        "array_3x2 = array_1d.reshape(3, 2)\n",
        "print(\"\\nReshaped to (3, 2):\")\n",
        "print(array_3x2)\n",
        "print(\"Shape:\", array_3x2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-zfW61_k2UP",
        "outputId": "6472ed60-1bc5-4250-9af2-0ba370719fbc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original 1D array: [1 2 3 4 5 6]\n",
            "Shape: (6,)\n",
            "\n",
            "Reshaped to (2, 3):\n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "Shape: (2, 3)\n",
            "\n",
            "Reshaped to (3, 2):\n",
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]]\n",
            "Shape: (3, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The original array has 6 elements. We can reshape it to any dimensions that multiply to 6: (2, 3), (3, 2), (6, 1), (1, 6). NumPy rearranges the elements to fill the new shape.\n",
        "\n",
        "If you try to reshape to dimensions that do not multiply to the original size, NumPy raises an error."
      ],
      "metadata": {
        "id": "2qS8lQHplF0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4.2 Understanding .reshape(-1, 1): The Magic of -1\n",
        "\n",
        "The -1 in reshape is a placeholder that tells NumPy to figure out the correct size automatically. When you write `.reshape(-1, 1)`, you are saying: give me a 2D array with 1 column, and calculate however many rows are needed.\n",
        "\n",
        "This is exactly what scikit-learn asked us to do in the error message."
      ],
      "metadata": {
        "id": "CLBE4YXwlH6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "momentum = np.array([0.05, 0.02, -0.03, 0.04, 0.01])\n",
        "\n",
        "print(\"Original 1D array:\", momentum)\n",
        "print(\"Shape:\", momentum.shape)\n",
        "\n",
        "# Reshape to 2D column vector\n",
        "momentum_2d = momentum.reshape(-1, 1)\n",
        "\n",
        "print(\"\\nReshaped with .reshape(-1, 1):\")\n",
        "print(momentum_2d)\n",
        "print(\"Shape:\", momentum_2d.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvV8fF7ilC3b",
        "outputId": "0dc3d6b1-cb79-4b2f-d830-7d95fbdd9651"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original 1D array: [ 0.05  0.02 -0.03  0.04  0.01]\n",
            "Shape: (5,)\n",
            "\n",
            "Reshaped with .reshape(-1, 1):\n",
            "[[ 0.05]\n",
            " [ 0.02]\n",
            " [-0.03]\n",
            " [ 0.04]\n",
            " [ 0.01]]\n",
            "Shape: (5, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The array went from shape `(5,)` to shape `(5, 1)`. NumPy calculated that -1 should be 5 because we have 5 elements and 1 column.\n",
        "\n",
        "The -1 is useful because it works regardless of how many elements your array has. You do not need to know the length in advance. This is important when your data size varies.\n",
        "\n",
        "Similarly, `.reshape(1, -1)` gives you a single row with as many columns as needed. This is used when you have a single sample with multiple features."
      ],
      "metadata": {
        "id": "uL5PbNBvlRHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4.3 .flatten() and .ravel(): Going Back to 1D\n",
        "\n",
        "Sometimes you need to go the other direction, from 2D back to 1D. The `.flatten()` and `.ravel()` methods both do this."
      ],
      "metadata": {
        "id": "D8l12aJ0lV2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "print(\"2D array:\")\n",
        "print(array_2d)\n",
        "print(\"Shape:\", array_2d.shape)\n",
        "\n",
        "# Using .flatten()\n",
        "flat = array_2d.flatten()\n",
        "print(\"\\nUsing .flatten():\", flat)\n",
        "print(\"Shape:\", flat.shape)\n",
        "\n",
        "# Using .ravel()\n",
        "raveled = array_2d.ravel()\n",
        "print(\"\\nUsing .ravel():\", raveled)\n",
        "print(\"Shape:\", raveled.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu7rJIN8lOJ_",
        "outputId": "0b845c32-db02-4b40-888f-de8667e576cf"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2D array:\n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "Shape: (2, 3)\n",
            "\n",
            "Using .flatten(): [1 2 3 4 5 6]\n",
            "Shape: (6,)\n",
            "\n",
            "Using .ravel(): [1 2 3 4 5 6]\n",
            "Shape: (6,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both methods produce the same result: a 1D array with all elements in row-major order (first row, then second row, and so on).\n",
        "\n",
        "The difference is technical. The `.flatten()` method always returns a copy of the data. The `.ravel()` method returns a view when possible, which is faster and uses less memory. For most purposes, they are interchangeable.\n",
        "\n",
        "When would you need to flatten?\n",
        "- When a function expects a 1D array and you have 2D data.\n",
        "- When you want to iterate over all elements.\n",
        "- When you need to pass data to a function that does not understand matrix structure."
      ],
      "metadata": {
        "id": "KF7O_xUjlaeM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4.4 Practical Example: Preparing Features for Sklearn\n",
        "\n",
        "Let's fix the error we saw earlier. We will reshape our momentum feature and successfully fit a linear regression model."
      ],
      "metadata": {
        "id": "1YOU_IjulgyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Our data\n",
        "momentum = np.array([0.05, 0.02, -0.03, 0.04, 0.01])\n",
        "next_returns = np.array([0.02, -0.01, 0.03, 0.01, 0.02])\n",
        "\n",
        "# Reshape momentum to 2D\n",
        "X = momentum.reshape(-1, 1)\n",
        "y = next_returns\n",
        "\n",
        "print(\"Before reshape:\", momentum.shape)\n",
        "print(\"After reshape:\", X.shape)\n",
        "print(\"Target shape:\", y.shape)\n",
        "\n",
        "# Now fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "print(\"\\nModel fitted successfully!\")\n",
        "print(\"Coefficient:\", model.coef_[0])\n",
        "print(\"Intercept:\", model.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZuNEArulYhY",
        "outputId": "5523d213-270e-4ab8-feb4-36bf4089cafb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before reshape: (5,)\n",
            "After reshape: (5, 1)\n",
            "Target shape: (5,)\n",
            "\n",
            "Model fitted successfully!\n",
            "Coefficient: -0.19587628865979378\n",
            "Intercept: 0.01752577319587629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One line of reshaping and the error is gone. The model fits successfully.\n",
        "\n",
        "This pattern will become second nature:\n",
        "\n",
        "1. Extract your features from a DataFrame\n",
        "2. Check the shape\n",
        "3. If 1D, reshape to (-1, 1)\n",
        "4. Pass to the model\n",
        "\n",
        "When you have multiple features, extracting multiple columns from a DataFrame already gives you a 2D array. The reshape is only needed for single-feature cases.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Zd6nFIYsls2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5 The Error Message Lab\n",
        "\n",
        "This section catalogs the most common shape-related errors you will encounter. When you see one of these in your own work, you will know exactly what went wrong and how to fix it."
      ],
      "metadata": {
        "id": "LE38xi7Hl1sg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5.1 Common Sklearn Shape Errors\n",
        "\n",
        "We have already seen the most common error: passing a 1D array when sklearn expects 2D. Here are the others you will encounter.\n",
        "\n",
        "**Error 1: Inconsistent number of samples**\n",
        "\n",
        "This happens when your features and target have different numbers of rows."
      ],
      "metadata": {
        "id": "IP_5DAUwl590"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features have 5 samples, target has 4\n",
        "X = np.array([[1], [2], [3], [4], [5]])\n",
        "y = np.array([0.1, 0.2, 0.3, 0.4])\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "try:\n",
        "    model.fit(X, y)\n",
        "except ValueError as e:\n",
        "    print(\"\\nError!\")\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oitQTTLNlrIt",
        "outputId": "783ecce7-6044-4a26-be34-b44c2e6c82db"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (5, 1)\n",
            "y shape: (4,)\n",
            "\n",
            "Error!\n",
            "Found input variables with inconsistent numbers of samples: [5, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The error message tells you the shapes do not match: X has 5 samples, y has 4. This usually happens when you accidentally dropped rows from one array but not the other, or when you sliced your data incorrectly.\n",
        "\n",
        "The fix: check where your data preparation went wrong. Make sure any filtering or cleaning operations are applied to both X and y together."
      ],
      "metadata": {
        "id": "4Se_5j9fl9Vl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Error 2: Single sample reshape confusion**\n",
        "\n",
        "This happens when you try to predict on a single observation and get the reshape wrong."
      ],
      "metadata": {
        "id": "RYbhpRibmB9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a model\n",
        "X_train = np.array([[1], [2], [3], [4], [5]])\n",
        "y_train = np.array([0.1, 0.2, 0.3, 0.4, 0.5])\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Try to predict on a single value\n",
        "new_observation = np.array([6])\n",
        "\n",
        "try:\n",
        "    prediction = model.predict(new_observation)\n",
        "except ValueError as e:\n",
        "    print(\"Error!\")\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG_KrBMyl4gk",
        "outputId": "9f4bb50d-5f0c-485f-dcd6-24fdf3a7d463"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error!\n",
            "Expected 2D array, got 1D array instead:\n",
            "array=[6].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same error again: expected 2D, got 1D. When predicting on new data, you must also reshape to 2D."
      ],
      "metadata": {
        "id": "hHg0PYiTmKwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The fix: reshape the single observation\n",
        "new_observation = np.array([6]).reshape(-1, 1)\n",
        "\n",
        "print(\"Reshaped observation shape:\", new_observation.shape)\n",
        "\n",
        "prediction = model.predict(new_observation)\n",
        "print(\"Prediction:\", prediction[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyWapH9VmDko",
        "outputId": "3e61c628-86ca-4f1d-8bb6-1e7d4688aec8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped observation shape: (1, 1)\n",
            "Prediction: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The observation now has shape `(1, 1)`: one sample with one feature. The model accepts it and returns a prediction.\n",
        "\n",
        "Remember: any data you pass to `.predict()` must have the same number of features as the data you trained on, and it must be 2D."
      ],
      "metadata": {
        "id": "ZlYz9LgtmPeh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5.2 Reading the Error Message\n",
        "\n",
        "Sklearn error messages are verbose but informative. Learning to read them quickly will speed up your debugging.\n",
        "\n",
        "Here is a strategy:\n",
        "\n",
        "1. Look for the word \"shape\" or \"dimension\" in the error message\n",
        "2. Find the numbers in parentheses, these are the actual shapes\n",
        "3. Compare what the function expected versus what it received\n",
        "4. Reshape accordingly\n",
        "\n",
        "Let's see one more example with multiple features."
      ],
      "metadata": {
        "id": "foaRcHNgmUkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a model with 3 features\n",
        "X_train = np.array([\n",
        "    [0.05, 0.15, 1000],\n",
        "    [0.02, 0.18, 1500],\n",
        "    [-0.03, 0.22, 1200],\n",
        "    [0.04, 0.19, 1800],\n",
        "    [0.01, 0.17, 1600]\n",
        "])\n",
        "y_train = np.array([0.02, -0.01, 0.03, 0.01, 0.02])\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model trained with X shape:\", X_train.shape)\n",
        "\n",
        "# Try to predict with only 2 features\n",
        "new_observation = np.array([[0.03, 0.16]])\n",
        "\n",
        "try:\n",
        "    prediction = model.predict(new_observation)\n",
        "except ValueError as e:\n",
        "    print(\"\\nError!\")\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2Sl4GoomNBw",
        "outputId": "d7991a65-78d4-4ca8-ae8f-5acc769509c3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained with X shape: (5, 3)\n",
            "\n",
            "Error!\n",
            "X has 2 features, but LinearRegression is expecting 3 features as input.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model was trained on 3 features but we tried to predict with only 2. The error message tells us exactly this: it expected 3 features but got 2.\n",
        "\n",
        "This happens when you forget to include all the features, or when your training and prediction data come from different sources with different columns.\n",
        "\n",
        "The fix: make sure your prediction data has the same features, in the same order, as your training data."
      ],
      "metadata": {
        "id": "-zyuzUzamYn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5.3 Fixing the Error Step by Step\n",
        "\n",
        "When you encounter a shape error, follow this checklist:\n",
        "\n",
        "**Step 1: Print the shapes**\n",
        "\n",
        "Before doing anything else, print the shape of every array involved.\n",
        "\n",
        "**Step 2: Identify the mismatch**\n",
        "\n",
        "Compare what you have versus what the function expects. Is it 1D vs 2D? Different number of samples? Different number of features?\n",
        "\n",
        "**Step 3: Trace back to the source**\n",
        "\n",
        "Where did the problematic array come from? Did you extract a single column? Did you filter rows? Did you forget to include all features?\n",
        "\n",
        "**Step 4: Apply the fix**\n",
        "\n",
        "- 1D to 2D column: `.reshape(-1, 1)`\n",
        "- 1D to 2D row: `.reshape(1, -1)`\n",
        "- 2D to 1D: `.flatten()` or `.ravel()`\n",
        "- Mismatched samples: check your data preparation\n",
        "- Mismatched features: ensure all features are included"
      ],
      "metadata": {
        "id": "XdySCxR1mjHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A complete debugging example\n",
        "def prepare_and_predict(features, target, new_data):\n",
        "    \"\"\"\n",
        "    A function that prints shapes at each step.\n",
        "    This is good practice during development.\n",
        "    \"\"\"\n",
        "    print(\"Step 1: Check input shapes\")\n",
        "    print(f\"  Features shape: {features.shape}\")\n",
        "    print(f\"  Target shape: {target.shape}\")\n",
        "    print(f\"  New data shape: {new_data.shape}\")\n",
        "\n",
        "    # Step 2: Fix shapes if needed\n",
        "    if features.ndim == 1:\n",
        "        print(\"\\n  Fixing: Features is 1D, reshaping to 2D\")\n",
        "        features = features.reshape(-1, 1)\n",
        "        print(f\"  New features shape: {features.shape}\")\n",
        "\n",
        "    if new_data.ndim == 1:\n",
        "        print(\"\\n  Fixing: New data is 1D, reshaping to 2D\")\n",
        "        new_data = new_data.reshape(-1, 1)\n",
        "        print(f\"  New data shape: {new_data.shape}\")\n",
        "\n",
        "    # Step 3: Verify compatibility\n",
        "    print(f\"\\nStep 2: Verify compatibility\")\n",
        "    print(f\"  Features has {features.shape[1]} feature(s)\")\n",
        "    print(f\"  New data has {new_data.shape[1]} feature(s)\")\n",
        "\n",
        "    if features.shape[1] != new_data.shape[1]:\n",
        "        raise ValueError(f\"Feature mismatch: trained on {features.shape[1]}, got {new_data.shape[1]}\")\n",
        "\n",
        "    # Step 4: Fit and predict\n",
        "    print(\"\\nStep 3: Fit and predict\")\n",
        "    model = LinearRegression()\n",
        "    model.fit(features, target)\n",
        "    prediction = model.predict(new_data)\n",
        "\n",
        "    return prediction\n",
        "\n",
        "# Test it\n",
        "momentum = np.array([0.05, 0.02, -0.03, 0.04, 0.01])\n",
        "returns = np.array([0.02, -0.01, 0.03, 0.01, 0.02])\n",
        "new_momentum = np.array([0.03])\n",
        "\n",
        "result = prepare_and_predict(momentum, returns, new_momentum)\n",
        "print(f\"\\nPrediction: {result[0]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dULmcvKumXK9",
        "outputId": "c05ad15d-5382-4373-a646-709da4ba79db"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Check input shapes\n",
            "  Features shape: (5,)\n",
            "  Target shape: (5,)\n",
            "  New data shape: (1,)\n",
            "\n",
            "  Fixing: Features is 1D, reshaping to 2D\n",
            "  New features shape: (5, 1)\n",
            "\n",
            "  Fixing: New data is 1D, reshaping to 2D\n",
            "  New data shape: (1, 1)\n",
            "\n",
            "Step 2: Verify compatibility\n",
            "  Features has 1 feature(s)\n",
            "  New data has 1 feature(s)\n",
            "\n",
            "Step 3: Fit and predict\n",
            "\n",
            "Prediction: 0.0116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function demonstrates defensive programming. By printing shapes at each step, you can see exactly what is happening. During development, this verbosity is valuable. Once your code is working, you can remove the print statements.\n",
        "\n",
        "The key lesson: shape errors are not mysterious. They follow predictable patterns and have straightforward fixes. Build the habit of checking shapes before passing data to any function.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "cICcCWoqmo7u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 What is Broadcasting?\n",
        "\n",
        "Broadcasting is one of NumPy's most powerful features. It allows you to perform operations on arrays of different shapes without explicitly copying data. This saves memory and makes your code cleaner.\n",
        "\n",
        "The basic idea: when you operate on two arrays of different shapes, NumPy automatically stretches the smaller array to match the larger one."
      ],
      "metadata": {
        "id": "cfusAGn6mvVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1.1 The Concept: Stretching Arrays to Match Shapes\n",
        "\n",
        "You have already seen broadcasting without knowing it. When you add a single number to an array, NumPy broadcasts that number across every element."
      ],
      "metadata": {
        "id": "U8OJao26m44M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prices = np.array([100, 102, 105, 103, 108])\n",
        "\n",
        "# Add a fixed fee to every price\n",
        "prices_with_fee = prices + 0.50\n",
        "\n",
        "print(\"Original prices:\", prices)\n",
        "print(\"After adding $0.50:\", prices_with_fee)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrNnDBhamnKd",
        "outputId": "1e3bc8a2-d878-41cc-b15e-4f4482f0eb6e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original prices: [100 102 105 103 108]\n",
            "After adding $0.50: [100.5 102.5 105.5 103.5 108.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy did not require you to create an array of five 0.50 values. It automatically broadcast the single value across the entire array.\n",
        "\n",
        "This works for any arithmetic operation: addition, subtraction, multiplication, division. It also works with more complex shape combinations."
      ],
      "metadata": {
        "id": "wIXpoAUTm8IW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1.2 The Rules of Broadcasting\n",
        "\n",
        "Broadcasting follows specific rules. NumPy compares shapes element by element, starting from the rightmost dimension:\n",
        "\n",
        "1. If the dimensions are equal, they are compatible.\n",
        "2. If one of the dimensions is 1, it is stretched to match the other.\n",
        "3. If neither condition is met, NumPy raises an error.\n",
        "\n",
        "Let's see these rules in action."
      ],
      "metadata": {
        "id": "TaKMLTYmnI53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rule 1: Equal dimensions are compatible\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([10, 20, 30])\n",
        "print(\"Equal shapes (3,) and (3,):\")\n",
        "print(f\"  {a} + {b} = {a + b}\")\n",
        "\n",
        "# Rule 2: Dimension of 1 is stretched\n",
        "# Array shape (3,) broadcast with scalar (treated as shape (1,))\n",
        "c = np.array([1, 2, 3])\n",
        "d = 10\n",
        "print(\"\\nShape (3,) with scalar:\")\n",
        "print(f\"  {c} * {d} = {c * d}\")\n",
        "\n",
        "# 2D example: (3, 3) with (3,)\n",
        "matrix = np.array([[1, 2, 3],\n",
        "                   [4, 5, 6],\n",
        "                   [7, 8, 9]])\n",
        "row = np.array([10, 20, 30])\n",
        "\n",
        "print(\"\\nShape (3, 3) with shape (3,):\")\n",
        "print(\"Matrix:\")\n",
        "print(matrix)\n",
        "print(f\"Row: {row}\")\n",
        "print(\"Result:\")\n",
        "print(matrix + row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In64Yikjm6c9",
        "outputId": "fe5dc7fc-e03e-4de1-efde-c51cf8f91ea0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Equal shapes (3,) and (3,):\n",
            "  [1 2 3] + [10 20 30] = [11 22 33]\n",
            "\n",
            "Shape (3,) with scalar:\n",
            "  [1 2 3] * 10 = [10 20 30]\n",
            "\n",
            "Shape (3, 3) with shape (3,):\n",
            "Matrix:\n",
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n",
            "Row: [10 20 30]\n",
            "Result:\n",
            "[[11 22 33]\n",
            " [14 25 36]\n",
            " [17 28 39]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the 2D example, the row array with shape `(3,)` was broadcast across each row of the matrix. NumPy stretched the 1D array to match the 2D shape, adding the same values to every row.\n",
        "\n",
        "This is extremely useful. You can subtract a mean from every row, multiply every row by different weights, or apply any element-wise operation without writing loops."
      ],
      "metadata": {
        "id": "ylhdIAllnNZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1.3 When Broadcasting Fails\n",
        "\n",
        "Broadcasting fails when the shapes are incompatible. This happens when neither dimension is equal and neither dimension is 1."
      ],
      "metadata": {
        "id": "_fOEZ2NdncDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Incompatible shapes: (3,) and (4,)\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([10, 20, 30, 40])\n",
        "\n",
        "print(\"Shape of a:\", a.shape)\n",
        "print(\"Shape of b:\", b.shape)\n",
        "\n",
        "try:\n",
        "    result = a + b\n",
        "except ValueError as e:\n",
        "    print(\"\\nError!\")\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgNXCxWinKhi",
        "outputId": "a157f616-9a7a-409a-9c4b-46bdfd1d7897"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of a: (3,)\n",
            "Shape of b: (4,)\n",
            "\n",
            "Error!\n",
            "operands could not be broadcast together with shapes (3,) (4,) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy cannot broadcast shapes `(3,)` and `(4,)` because neither dimension matches and neither is 1. There is no sensible way to stretch 3 elements to match 4 elements.\n",
        "\n",
        "When you see a broadcasting error, check the shapes of both arrays. Usually the fix is to reshape one of them so the dimensions align properly.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "6z1NTosxnkrj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Practical Examples\n",
        "\n",
        "Broadcasting is not just a technical feature. It simplifies real financial calculations. Here are the patterns you will use most often."
      ],
      "metadata": {
        "id": "n1H04JwJnsRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.1 Subtracting the Risk-Free Rate from Returns\n",
        "\n",
        "When calculating excess returns or the Sharpe ratio, you need to subtract the risk-free rate from every return in your series. Broadcasting makes this trivial."
      ],
      "metadata": {
        "id": "l_AKNTxWntzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Monthly returns for a portfolio\n",
        "monthly_returns = np.array([0.02, -0.01, 0.03, 0.015, -0.005, 0.025])\n",
        "\n",
        "# Risk-free rate (monthly)\n",
        "risk_free_rate = 0.004  # Approximately 5% annual\n",
        "\n",
        "# Calculate excess returns\n",
        "excess_returns = monthly_returns - risk_free_rate\n",
        "\n",
        "print(\"Monthly returns:\", monthly_returns)\n",
        "print(\"Risk-free rate:\", risk_free_rate)\n",
        "print(\"Excess returns:\", excess_returns)\n",
        "print(f\"\\nMean excess return: {np.mean(excess_returns):.4f}\")\n",
        "print(f\"Sharpe ratio (annualized): {np.mean(excess_returns) / np.std(excess_returns) * np.sqrt(12):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVOh-d5NndbB",
        "outputId": "c119ebc7-2c48-4b77-c7c1-f86d1b71af17"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monthly returns: [ 0.02  -0.01   0.03   0.015 -0.005  0.025]\n",
            "Risk-free rate: 0.004\n",
            "Excess returns: [ 0.016 -0.014  0.026  0.011 -0.009  0.021]\n",
            "\n",
            "Mean excess return: 0.0085\n",
            "Sharpe ratio (annualized): 1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The single risk-free rate value was broadcast across the entire returns array. Each element had the same value subtracted. No loop required.\n",
        "\n",
        "This is the foundation of risk-adjusted performance measurement. The Sharpe ratio, Sortino ratio, and information ratio all start with calculating excess returns in exactly this way.\n",
        "\n",
        "Note: a Sharpe ratio of 1.97 is incredibly good! Almost too good. We will spend a lot of time on this in future chapters."
      ],
      "metadata": {
        "id": "vKHth9Q5nyHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.2 Normalizing Returns (Mean Zero, Unit Variance)\n",
        "\n",
        "Many machine learning algorithms perform better when features are normalized. A common approach is to subtract the mean and divide by the standard deviation, creating a series with mean zero and standard deviation of one."
      ],
      "metadata": {
        "id": "LiTWqRRO2wme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Raw returns for an asset\n",
        "returns = np.array([0.02, -0.01, 0.03, 0.015, -0.005, 0.025, 0.01, -0.02])\n",
        "\n",
        "# Calculate mean and standard deviation\n",
        "mean_return = np.mean(returns)\n",
        "std_return = np.std(returns)\n",
        "\n",
        "# Normalize using broadcasting\n",
        "normalized_returns = (returns - mean_return) / std_return\n",
        "\n",
        "print(\"Original returns:\", returns)\n",
        "print(f\"Mean: {mean_return:.4f}\")\n",
        "print(f\"Std:  {std_return:.4f}\")\n",
        "print(\"\\nNormalized returns:\", normalized_returns)\n",
        "print(f\"Normalized mean: {np.mean(normalized_returns):.10f}\")\n",
        "print(f\"Normalized std:  {np.std(normalized_returns):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YirTJ_3YnvPj",
        "outputId": "e1ace134-968c-44ec-a7f2-6feba71dcd35"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original returns: [ 0.02  -0.01   0.03   0.015 -0.005  0.025  0.01  -0.02 ]\n",
            "Mean: 0.0081\n",
            "Std:  0.0168\n",
            "\n",
            "Normalized returns: [ 0.70858043 -1.0815175   1.30527975  0.41023078 -0.78316785  1.00693009\n",
            "  0.11188112 -1.67821682]\n",
            "Normalized mean: -0.0000000000\n",
            "Normalized std:  1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two broadcasting operations in one line. First, the mean is subtracted from every element. Then, every element is divided by the standard deviation.\n",
        "\n",
        "The result has a mean of essentially zero (the tiny number is floating point error) and a standard deviation of 1. This is called standardization or z-score normalization.\n",
        "\n",
        "When preparing features for machine learning, you will often normalize each feature column this way. It prevents features with large values from dominating features with small values."
      ],
      "metadata": {
        "id": "hhm5vUAU22ld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.3 Calculating Excess Returns vs. a Benchmark\n",
        "\n",
        "When evaluating a portfolio, you often want to compare its returns against a benchmark like the S&P 500. Broadcasting lets you do this across multiple assets at once."
      ],
      "metadata": {
        "id": "8DZIfNAs3C7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns for 4 stocks over 5 days (rows are stocks, columns are days)\n",
        "stock_returns = np.array([\n",
        "    [0.01, 0.02, -0.01, 0.03, 0.01],   # Stock A\n",
        "    [0.02, -0.01, 0.02, 0.01, -0.02],  # Stock B\n",
        "    [-0.01, 0.03, 0.01, 0.02, 0.01],   # Stock C\n",
        "    [0.015, 0.01, -0.02, 0.025, 0.005] # Stock D\n",
        "])\n",
        "\n",
        "# Benchmark returns (S&P 500) for the same 5 days\n",
        "benchmark_returns = np.array([0.005, 0.01, -0.005, 0.015, 0.002])\n",
        "\n",
        "print(\"Stock returns shape:\", stock_returns.shape)\n",
        "print(\"Benchmark returns shape:\", benchmark_returns.shape)\n",
        "\n",
        "# Calculate excess returns for all stocks\n",
        "excess_vs_benchmark = stock_returns - benchmark_returns\n",
        "\n",
        "print(\"\\nStock returns:\")\n",
        "print(stock_returns)\n",
        "print(\"\\nBenchmark returns:\", benchmark_returns)\n",
        "print(\"\\nExcess returns vs benchmark:\")\n",
        "print(excess_vs_benchmark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaOYRPGJ2yg0",
        "outputId": "cf559d41-0259-4140-f20d-5e841c0d4454"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock returns shape: (4, 5)\n",
            "Benchmark returns shape: (5,)\n",
            "\n",
            "Stock returns:\n",
            "[[ 0.01   0.02  -0.01   0.03   0.01 ]\n",
            " [ 0.02  -0.01   0.02   0.01  -0.02 ]\n",
            " [-0.01   0.03   0.01   0.02   0.01 ]\n",
            " [ 0.015  0.01  -0.02   0.025  0.005]]\n",
            "\n",
            "Benchmark returns: [ 0.005  0.01  -0.005  0.015  0.002]\n",
            "\n",
            "Excess returns vs benchmark:\n",
            "[[ 0.005  0.01  -0.005  0.015  0.008]\n",
            " [ 0.015 -0.02   0.025 -0.005 -0.022]\n",
            " [-0.015  0.02   0.015  0.005  0.008]\n",
            " [ 0.01   0.    -0.015  0.01   0.003]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The benchmark array with shape `(5,)` was broadcast across each row of the stock returns matrix with shape `(4, 5)`. Each stock's daily return had the corresponding benchmark return subtracted.\n",
        "\n",
        "This gives you the daily excess return for every stock in a single operation. Positive values mean the stock outperformed the benchmark that day. Negative values mean it underperformed.\n",
        "\n",
        "From here, you could calculate tracking error, information ratio, or identify which stocks consistently beat the benchmark.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "SrbHvQ8G3KUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1 Array Math for Finance\n",
        "\n",
        "This section covers the matrix operations and statistical functions that appear constantly in quantitative finance. Portfolio optimization, risk analysis, and factor models all rely on these tools."
      ],
      "metadata": {
        "id": "kF9_jPGp3RFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1.1 np.dot(): Dot Product (Portfolio Weights x Returns)\n",
        "\n",
        "The dot product is the foundation of portfolio return calculation. We covered this earlier, but let's examine it more closely.\n",
        "\n",
        "When you multiply portfolio weights by asset returns, you are computing a weighted sum. This is exactly what the dot product does."
      ],
      "metadata": {
        "id": "6zO_19_t3SaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Portfolio weights (must sum to 1)\n",
        "weights = np.array([0.4, 0.35, 0.25])\n",
        "\n",
        "# Daily returns for 3 assets\n",
        "returns = np.array([0.02, -0.01, 0.03])\n",
        "\n",
        "# Portfolio return = weighted sum of individual returns\n",
        "portfolio_return = np.dot(weights, returns)\n",
        "\n",
        "print(\"Weights:\", weights)\n",
        "print(\"Returns:\", returns)\n",
        "print(f\"\\nPortfolio return: {portfolio_return:.4f}\")\n",
        "\n",
        "# Manual calculation to verify\n",
        "manual = (0.4 * 0.02) + (0.35 * -0.01) + (0.25 * 0.03)\n",
        "print(f\"Manual calculation: {manual:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwdLbTcK3E3N",
        "outputId": "f9055b1a-6bb4-42ac-b7bd-7a1112bd5436"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights: [0.4  0.35 0.25]\n",
            "Returns: [ 0.02 -0.01  0.03]\n",
            "\n",
            "Portfolio return: 0.0120\n",
            "Manual calculation: 0.0120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dot product multiplies corresponding elements and sums the results. For portfolio returns, this gives you the weighted average return.\n",
        "\n",
        "This operation scales beautifully. Whether you have 3 assets or 3,000, the syntax is the same. NumPy handles the computation efficiently regardless of size."
      ],
      "metadata": {
        "id": "rR3n5oSQ3Vvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1.2 The @ Operator: Matrix Multiplication\n",
        "\n",
        "Python 3.5 introduced the `@` operator for matrix multiplication. It does the same thing as `np.dot()` but is cleaner to read, especially for complex expressions."
      ],
      "metadata": {
        "id": "KUWhfoVa3dpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Same calculation using @ operator\n",
        "weights = np.array([0.4, 0.35, 0.25])\n",
        "returns = np.array([0.02, -0.01, 0.03])\n",
        "\n",
        "portfolio_return = weights @ returns\n",
        "\n",
        "print(\"Using @ operator:\", portfolio_return)\n",
        "\n",
        "# Where @ really shines: matrix multiplication\n",
        "# Returns matrix: 3 assets over 5 days\n",
        "returns_matrix = np.array([\n",
        "    [0.01, 0.02, -0.01, 0.03, 0.01],\n",
        "    [0.02, -0.01, 0.02, 0.01, -0.02],\n",
        "    [-0.01, 0.03, 0.01, 0.02, 0.01]\n",
        "])\n",
        "\n",
        "# Portfolio returns for all 5 days in one operation\n",
        "portfolio_returns = weights @ returns_matrix\n",
        "\n",
        "print(\"\\nWeights shape:\", weights.shape)\n",
        "print(\"Returns matrix shape:\", returns_matrix.shape)\n",
        "print(\"Portfolio returns for each day:\", portfolio_returns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_-ll7fi3UBI",
        "outputId": "383891c6-0f46-421f-c395-3354c48348b5"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using @ operator: 0.012\n",
            "\n",
            "Weights shape: (3,)\n",
            "Returns matrix shape: (3, 5)\n",
            "Portfolio returns for each day: [ 0.0085  0.012   0.0055  0.0205 -0.0005]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `@` operator makes the code more readable, especially when you chain multiple matrix operations together. Compare:\n",
        "\n",
        "`result = np.dot(np.dot(A, B), C)` versus `result = A @ B @ C`\n",
        "\n",
        "For portfolio calculations, use whichever you find clearer. Both produce identical results. In this book, you will see both depending on what makes the code easier to understand."
      ],
      "metadata": {
        "id": "pTcxMO4j31oD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1.3 np.transpose(): Transposing Arrays\n",
        "\n",
        "Transposing swaps rows and columns. A matrix with shape `(3, 5)` becomes shape `(5, 3)`. This is essential when your data is organized one way but a calculation requires it the other way."
      ],
      "metadata": {
        "id": "uwYCmwmA37QB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns matrix: 3 assets (rows) over 5 days (columns)\n",
        "returns = np.array([\n",
        "    [0.01, 0.02, -0.01, 0.03, 0.01],\n",
        "    [0.02, -0.01, 0.02, 0.01, -0.02],\n",
        "    [-0.01, 0.03, 0.01, 0.02, 0.01]\n",
        "])\n",
        "\n",
        "print(\"Original shape:\", returns.shape)\n",
        "print(\"Original (assets as rows):\")\n",
        "print(returns)\n",
        "\n",
        "# Transpose: now days are rows, assets are columns\n",
        "returns_T = np.transpose(returns)\n",
        "\n",
        "print(\"\\nTransposed shape:\", returns_T.shape)\n",
        "print(\"Transposed (days as rows):\")\n",
        "print(returns_T)\n",
        "\n",
        "# Shorthand: .T attribute\n",
        "print(\"\\nUsing .T attribute:\", returns.T.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mU4cOXnF3z-h",
        "outputId": "36c8dd1c-a5d2-4714-d349-5382a3183310"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (3, 5)\n",
            "Original (assets as rows):\n",
            "[[ 0.01  0.02 -0.01  0.03  0.01]\n",
            " [ 0.02 -0.01  0.02  0.01 -0.02]\n",
            " [-0.01  0.03  0.01  0.02  0.01]]\n",
            "\n",
            "Transposed shape: (5, 3)\n",
            "Transposed (days as rows):\n",
            "[[ 0.01  0.02 -0.01]\n",
            " [ 0.02 -0.01  0.03]\n",
            " [-0.01  0.02  0.01]\n",
            " [ 0.03  0.01  0.02]\n",
            " [ 0.01 -0.02  0.01]]\n",
            "\n",
            "Using .T attribute: (5, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy provides two ways to transpose an array. The `np.transpose()` function and the `.T` attribute. The `.T` attribute is simply a shortcut that does the same thing with less typing.\n",
        "\n",
        "For 2D arrays, they are identical. Use `.T` when you want concise code. Use `np.transpose()` when you want to be explicit or when working with arrays of three or more dimensions, where `np.transpose()` allows you to specify the exact axis order.\n",
        "\n",
        "For the 1D and 2D arrays you will encounter in most financial work, `.T` is the common choice.\n",
        "\n",
        "You will need to transpose when:\n",
        "\n",
        "- Your data has assets as rows but a function expects assets as columns\n",
        "- You are computing a covariance matrix and need to align the dimensions\n",
        "- You are converting between different data organization conventions\n",
        "\n",
        "The key is knowing how your data is organized and how the function you are calling expects it to be organized.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "h0ifLYG64BJO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 Statistical Functions\n",
        "\n",
        "NumPy provides efficient implementations of the statistical calculations you need for risk analysis and portfolio management. These functions operate on entire arrays without loops."
      ],
      "metadata": {
        "id": "a34v6gs-7uoc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2.1 np.mean(), np.std(), np.var()\n",
        "\n",
        "These are the building blocks of performance and risk measurement. Mean return tells you the average performance. Standard deviation and variance measure volatility."
      ],
      "metadata": {
        "id": "Y-9m3YzI7xTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Monthly returns for a portfolio\n",
        "returns = np.array([0.02, -0.01, 0.03, 0.015, -0.02, 0.025, 0.01, -0.005, 0.018, 0.022, -0.008, 0.012])\n",
        "\n",
        "print(\"Monthly returns:\", returns)\n",
        "print(f\"\\nMean monthly return: {np.mean(returns):.4f}\")\n",
        "print(f\"Standard deviation: {np.std(returns):.4f}\")\n",
        "print(f\"Variance: {np.var(returns):.6f}\")\n",
        "\n",
        "# Annualize the statistics (assuming monthly data)\n",
        "annual_return = np.mean(returns) * 12\n",
        "annual_volatility = np.std(returns) * np.sqrt(12)\n",
        "\n",
        "print(f\"\\nAnnualized return: {annual_return:.2%}\")\n",
        "print(f\"Annualized volatility: {annual_volatility:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqrSMWSU3_aa",
        "outputId": "f1a3a0e4-e273-4094-a8a8-fe8d2c09b755"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monthly returns: [ 0.02  -0.01   0.03   0.015 -0.02   0.025  0.01  -0.005  0.018  0.022\n",
            " -0.008  0.012]\n",
            "\n",
            "Mean monthly return: 0.0091\n",
            "Standard deviation: 0.0153\n",
            "Variance: 0.000233\n",
            "\n",
            "Annualized return: 10.90%\n",
            "Annualized volatility: 5.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The annualization formulas are standard in finance. Returns scale linearly with time, so you multiply by 12 for monthly data. Volatility scales with the square root of time, so you multiply by the square root of 12.\n",
        "\n",
        "Note that `np.std()` by default calculates the population standard deviation (dividing by n). If you want the sample standard deviation (dividing by n-1), use `np.std(returns, ddof=1)`. For large datasets, the difference is negligible. For small samples, it matters."
      ],
      "metadata": {
        "id": "HH3vLfUF70Ay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2.2 np.corrcoef(): Correlation Matrix\n",
        "\n",
        "Correlation measures how two assets move together. A correlation of 1 means they move in perfect lockstep. A correlation of -1 means they move in opposite directions. A correlation near 0 means their movements are unrelated.\n",
        "\n",
        "The correlation matrix shows the correlation between every pair of assets in your portfolio. It is essential for diversification analysis and risk management."
      ],
      "metadata": {
        "id": "F5sRn5wV8zHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns for 4 assets over 10 periods\n",
        "np.random.seed(42)\n",
        "stock_a = np.random.normal(0.01, 0.02, 10)\n",
        "stock_b = stock_a * 0.8 + np.random.normal(0, 0.01, 10)  # Correlated with A\n",
        "stock_c = np.random.normal(0.005, 0.025, 10)              # Independent\n",
        "stock_d = -stock_a * 0.5 + np.random.normal(0, 0.015, 10) # Negatively correlated with A\n",
        "\n",
        "returns = np.array([stock_a, stock_b, stock_c, stock_d])\n",
        "\n",
        "print(\"Returns shape:\", returns.shape)\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = np.corrcoef(returns)\n",
        "\n",
        "print(\"\\nCorrelation Matrix:\")\n",
        "print(np.round(correlation_matrix, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KopgQKS97y0s",
        "outputId": "22ff8e9c-3243-45c1-eb3d-bea72ced66c4"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Returns shape: (4, 10)\n",
            "\n",
            "Correlation Matrix:\n",
            "[[ 1.    0.82 -0.32 -0.5 ]\n",
            " [ 0.82  1.    0.09 -0.53]\n",
            " [-0.32  0.09  1.   -0.02]\n",
            " [-0.5  -0.53 -0.02  1.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The correlation matrix is always square, with 1s on the diagonal (each asset is perfectly correlated with itself).\n",
        "\n",
        "Look at the results:\n",
        "\n",
        "- Stock A and Stock B have high positive correlation (we constructed B from A)\n",
        "- Stock A and Stock D have negative correlation (we constructed D as the inverse of A)\n",
        "- Stock C is relatively uncorrelated with the others (we generated it independently)\n",
        "\n",
        "This matrix tells you which assets provide diversification benefits. Adding highly correlated assets does little to reduce risk. Adding uncorrelated or negatively correlated assets reduces portfolio volatility."
      ],
      "metadata": {
        "id": "RTU5gF4A-Gdw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2.3 np.cov(): Covariance Matrix\n",
        "\n",
        "Covariance is related to correlation but includes the magnitude of the movements, not just the direction. The covariance matrix is essential for portfolio optimization because it captures both the volatility of each asset and how assets move together.\n",
        "\n",
        "The relationship is: correlation = covariance / (std_a  std_b)"
      ],
      "metadata": {
        "id": "jB2El1Db-Mvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the same returns from the correlation example\n",
        "covariance_matrix = np.cov(returns)\n",
        "\n",
        "print(\"Covariance Matrix:\")\n",
        "print(np.round(covariance_matrix, 6))\n",
        "\n",
        "print(\"\\nDiagonal elements (variances):\")\n",
        "for i, var in enumerate(np.diag(covariance_matrix)):\n",
        "    print(f\"  Asset {i}: variance = {var:.6f}, std = {np.sqrt(var):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHnayLjn81Og",
        "outputId": "62f40a56-ef47-451e-d4be-847b8c4cbd26"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Covariance Matrix:\n",
            "[[ 2.09e-04  1.55e-04 -9.30e-05 -1.42e-04]\n",
            " [ 1.55e-04  1.72e-04  2.40e-05 -1.35e-04]\n",
            " [-9.30e-05  2.40e-05  4.14e-04 -8.00e-06]\n",
            " [-1.42e-04 -1.35e-04 -8.00e-06  3.85e-04]]\n",
            "\n",
            "Diagonal elements (variances):\n",
            "  Asset 0: variance = 0.000209, std = 0.0145\n",
            "  Asset 1: variance = 0.000172, std = 0.0131\n",
            "  Asset 2: variance = 0.000414, std = 0.0203\n",
            "  Asset 3: variance = 0.000385, std = 0.0196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The diagonal of the covariance matrix contains the variance of each asset. The off-diagonal elements contain the covariances between pairs of assets.\n",
        "\n",
        "The covariance matrix is the key input for mean-variance optimization. When you calculate portfolio variance, you use the formula:\n",
        "\n",
        "portfolio_variance = weights.T @ covariance_matrix @ weights\n",
        "\n",
        "We will see this calculation shortly."
      ],
      "metadata": {
        "id": "yocdug56-QMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2.4 np.percentile(): Quantiles for Risk Analysis\n",
        "\n",
        "Percentiles tell you what percentage of observations fall below a given value. In risk management, percentiles are used to calculate Value at Risk (VaR), identify outliers, and understand the distribution of returns."
      ],
      "metadata": {
        "id": "QlWz4eIe-ZrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulated daily returns for a year\n",
        "np.random.seed(42)\n",
        "daily_returns = np.random.normal(0.0005, 0.015, 252)\n",
        "\n",
        "print(f\"Number of observations: {len(daily_returns)}\")\n",
        "print(f\"Mean return: {np.mean(daily_returns):.4f}\")\n",
        "print(f\"Std deviation: {np.std(daily_returns):.4f}\")\n",
        "\n",
        "# Calculate percentiles\n",
        "percentile_5 = np.percentile(daily_returns, 5)\n",
        "percentile_25 = np.percentile(daily_returns, 25)\n",
        "percentile_50 = np.percentile(daily_returns, 50)  # Median\n",
        "percentile_75 = np.percentile(daily_returns, 75)\n",
        "percentile_95 = np.percentile(daily_returns, 95)\n",
        "\n",
        "print(f\"\\n5th percentile:  {percentile_5:.4f}\")\n",
        "print(f\"25th percentile: {percentile_25:.4f}\")\n",
        "print(f\"50th percentile (median): {percentile_50:.4f}\")\n",
        "print(f\"75th percentile: {percentile_75:.4f}\")\n",
        "print(f\"95th percentile: {percentile_95:.4f}\")\n",
        "\n",
        "# Value at Risk (VaR) at 95% confidence\n",
        "var_95 = np.percentile(daily_returns, 5)\n",
        "print(f\"\\n95% VaR (daily): {var_95:.4f}\")\n",
        "print(f\"Interpretation: On 95% of days, losses will not exceed {-var_95:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5BapgkR-OZ7",
        "outputId": "cc7ca541-45da-4094-a914-e41218d4640e"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of observations: 252\n",
            "Mean return: 0.0004\n",
            "Std deviation: 0.0145\n",
            "\n",
            "5th percentile:  -0.0219\n",
            "25th percentile: -0.0098\n",
            "50th percentile (median): 0.0014\n",
            "75th percentile: 0.0094\n",
            "95th percentile: 0.0238\n",
            "\n",
            "95% VaR (daily): -0.0219\n",
            "Interpretation: On 95% of days, losses will not exceed 2.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 5th percentile tells you the return that 5% of observations fall below. In risk terms, this is the 95% Value at Risk: the loss you would expect to exceed only 5% of the time.\n",
        "\n",
        "Note that VaR is typically expressed as a positive number representing a loss. If the 5th percentile is -0.024, your 95% VaR is 2.4%. This means on 95% of days, you would not expect to lose more than 2.4% of your portfolio value.\n",
        "\n",
        "Percentiles are also useful for identifying extreme returns. Returns below the 1st percentile or above the 99th percentile are often considered outliers worth investigating.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "TYNceurn-c52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3 Financial Calculations\n",
        "\n",
        "Let's bring together everything we have learned to perform the core calculations of portfolio management. These examples demonstrate why NumPy is essential for quantitative finance."
      ],
      "metadata": {
        "id": "v2cKc_Vn-nul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3.1 Portfolio Return: Weights Dot Returns\n",
        "\n",
        "We have seen this calculation several times. Here it is in its complete form, starting from raw price data."
      ],
      "metadata": {
        "id": "E0eSXCIo-pfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulated closing prices for 3 assets over 10 days\n",
        "np.random.seed(42)\n",
        "prices = np.array([\n",
        "    100 * np.cumprod(1 + np.random.normal(0.001, 0.02, 10)),  # Asset A\n",
        "    50 * np.cumprod(1 + np.random.normal(0.0005, 0.015, 10)), # Asset B\n",
        "    75 * np.cumprod(1 + np.random.normal(0.0008, 0.018, 10))  # Asset C\n",
        "])\n",
        "\n",
        "# Calculate returns (each row is an asset)\n",
        "returns = prices[:, 1:] / prices[:, :-1] - 1\n",
        "\n",
        "print(\"Prices shape:\", prices.shape)\n",
        "print(\"Returns shape:\", returns.shape)\n",
        "\n",
        "# Portfolio weights\n",
        "weights = np.array([0.5, 0.3, 0.2])\n",
        "\n",
        "# Calculate portfolio return for each day\n",
        "portfolio_returns = weights @ returns\n",
        "\n",
        "print(\"\\nPortfolio weights:\", weights)\n",
        "print(\"Daily portfolio returns:\", np.round(portfolio_returns, 4))\n",
        "print(f\"\\nTotal portfolio return: {np.sum(portfolio_returns):.4f}\")\n",
        "print(f\"Mean daily return: {np.mean(portfolio_returns):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psqRAGUd-bX7",
        "outputId": "525aea82-9800-4e21-b1f6-d969be635298"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prices shape: (3, 10)\n",
            "Returns shape: (3, 9)\n",
            "\n",
            "Portfolio weights: [0.5 0.3 0.2]\n",
            "Daily portfolio returns: [-0.0035  0.0086  0.0023 -0.0113 -0.0037  0.0079  0.0113 -0.0101 -0.0012]\n",
            "\n",
            "Total portfolio return: 0.0004\n",
            "Mean daily return: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the complete workflow: prices to returns to portfolio returns. The matrix multiplication handles all assets and all days in a single operation.\n",
        "\n",
        "Note the slicing used to calculate returns: `prices[:, 1:]` gives all rows from column 1 onward, and `prices[:, :-1]` gives all rows except the last column. This is the NumPy equivalent of the `.shift()` pattern we use in Pandas."
      ],
      "metadata": {
        "id": "p8IDqADA-sd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3.2 Portfolio Variance: w.T @ Cov @ w\n",
        "\n",
        "Portfolio variance measures the total risk of your portfolio. It accounts for both the volatility of individual assets and how they move together. The formula is:\n",
        "\n",
        "portfolio_variance = w.T @  @ w\n",
        "\n",
        "Where w is the weight vector and  (sigma) is the covariance matrix."
      ],
      "metadata": {
        "id": "HN2SWS6l-zjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the returns from the previous example\n",
        "# Calculate the covariance matrix\n",
        "cov_matrix = np.cov(returns)\n",
        "\n",
        "print(\"Covariance Matrix:\")\n",
        "print(np.round(cov_matrix, 6))\n",
        "\n",
        "# Portfolio weights\n",
        "weights = np.array([0.5, 0.3, 0.2])\n",
        "\n",
        "# Portfolio variance: w.T @ Cov @ w\n",
        "portfolio_variance = weights.T @ cov_matrix @ weights\n",
        "portfolio_volatility = np.sqrt(portfolio_variance)\n",
        "\n",
        "print(f\"\\nPortfolio weights: {weights}\")\n",
        "print(f\"Portfolio variance: {portfolio_variance:.6f}\")\n",
        "print(f\"Portfolio volatility (daily): {portfolio_volatility:.4f}\")\n",
        "print(f\"Portfolio volatility (annualized): {portfolio_volatility * np.sqrt(252):.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QuEUbP7-rHU",
        "outputId": "ea512ec2-efd5-4947-b054-267ccb192b59"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Covariance Matrix:\n",
            "[[ 2.35e-04 -2.10e-05 -8.00e-05]\n",
            " [-2.10e-05  1.41e-04  9.80e-05]\n",
            " [-8.00e-05  9.80e-05  1.13e-04]]\n",
            "\n",
            "Portfolio weights: [0.5 0.3 0.2]\n",
            "Portfolio variance: 0.000066\n",
            "Portfolio volatility (daily): 0.0081\n",
            "Portfolio volatility (annualized): 12.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This single line, `weights.T @ cov_matrix @ weights`, is the heart of mean-variance optimization. It tells you the risk of any portfolio given its weights.\n",
        "\n",
        "Notice that portfolio volatility is not simply the weighted average of individual volatilities. Because assets are not perfectly correlated, diversification reduces overall risk. This is why the covariance matrix matters: it captures the diversification benefit.\n",
        "\n",
        "In portfolio optimization, you search for the weights that minimize this variance for a given target return, or maximize return for a given variance. The math is the same; only the objective changes."
      ],
      "metadata": {
        "id": "UGPTDepY-3fL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 Conclusion\n",
        "\n",
        "You now have the NumPy foundation you need for quantitative finance. Let's recap what you learned:\n",
        "\n",
        "**Arrays vs DataFrames:** Arrays are fast and unlabeled. DataFrames are convenient and labeled. Use Pandas for data preparation and exploration. Use NumPy for computation and machine learning.\n",
        "\n",
        "**Vectorization:** Think in arrays, not loops. Vectorized operations are faster and cleaner. When you catch yourself writing a for loop over numerical data, pause and look for a vectorized solution.\n",
        "\n",
        "**Shape:** Most errors in machine learning come from shape mismatches. A 1D array with shape `(n,)` is not the same as a 2D array with shape `(n, 1)`. Use `.reshape(-1, 1)` to fix single-feature inputs.\n",
        "\n",
        "**Broadcasting:** NumPy stretches smaller arrays to match larger ones. This simplifies calculations like subtracting the risk-free rate or normalizing returns.\n",
        "\n",
        "**Matrix Operations:** Portfolio returns are a dot product. Portfolio variance uses the covariance matrix. These calculations scale to any number of assets."
      ],
      "metadata": {
        "id": "Odyl9_In_GYd"
      }
    }
  ]
}